{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Notes:**\n",
        "\n",
        "<mark>請在左上方選擇 [檔案] >> [在雲端硬碟中儲存複本]，</mark>\n",
        "\n",
        "<mark>並於您創建的複本中操作（此colab僅供檢視）</mark>\n",
        "\n",
        "- The goal of this notebook is to provide an introduction of the use cases in LangChain.\n",
        "\n",
        "- This notebook is based on the [LangChain Tutorial](https://github.com/gkamradt/langchain-tutorials) (by Greg Kamradt) and the LangChain [Documentation](https://docs.langchain.com/docs/).\n",
        "\n",
        "- The default models (`davinci-003` and `gpt-3.5-turbo`) are used throughout the notebook; `gpt-4.0` would surely get better results.\n",
        "- A   <mark>paid</mark> `OPENAI_API_KEY` is required to run the code blocks involving LLMs."
      ],
      "metadata": {
        "id": "MKUHiEnLCKX-"
      },
      "id": "MKUHiEnLCKX-"
    },
    {
      "cell_type": "markdown",
      "id": "11d788b0",
      "metadata": {
        "id": "11d788b0"
      },
      "source": [
        "\n",
        "## **Setup**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9815081",
      "metadata": {
        "hide_input": false,
        "id": "e9815081"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# if we have a .env file in the root directory\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY', 'PasteYourAPIkeyHere_IfNoEnv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specific version\n",
        "!pip install -q langchain==0.0.309\n",
        "!pip install -q openai\n",
        "!pip install -q python-dotenv tiktoken chromadb p_tqdm tqdm bs4 weaviate-client"
      ],
      "metadata": {
        "id": "A55-cdePFwTY"
      },
      "id": "A55-cdePFwTY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands-on cases for today**\n",
        "1️⃣ Basic components\n",
        "\n",
        "2️⃣ Vectorize Data to Weaviate\n",
        "\n",
        "3️⃣ Retrieving data from Weaviate\n",
        "\n",
        "4️⃣ Q&A over specific context\n",
        "\n",
        "5️⃣ Summarization\n",
        "\n",
        "Agents (if time permits)\n"
      ],
      "metadata": {
        "id": "cXjfRbdI2n9X"
      },
      "id": "cXjfRbdI2n9X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "coJQWBNvySAt"
      },
      "id": "coJQWBNvySAt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1️⃣ Basic components**\n",
        "\n",
        "- `LLM`, `PromptTemplate`, `OutputParser`\n",
        "\n",
        "  ➡️ Integrating the above components as a chain\n",
        "- Loading and saving a chain"
      ],
      "metadata": {
        "id": "KgncsV9c1Hp0"
      },
      "id": "KgncsV9c1Hp0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<mark>**LLM**</mark>\n",
        "\n",
        "`llm.predict()`"
      ],
      "metadata": {
        "id": "qezZzO462BNJ"
      },
      "id": "qezZzO462BNJ"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "chat_model = ChatOpenAI()"
      ],
      "metadata": {
        "id": "1XkHy6jE1K0J"
      },
      "id": "1XkHy6jE1K0J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a cute company name for a company that makes cake?\"\n",
        "\n",
        "p = llm.predict(text)\n",
        "print(p)\n",
        "print(\"===========\")\n",
        "\n",
        "p = chat_model.predict(text)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za68brYL1PmA",
        "outputId": "b3c16feb-0df9-4d8e-d731-20e54171d4c2"
      },
      "id": "Za68brYL1PmA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sweet Tooth Bakery.\n",
            "===========\n",
            "Sweet Delights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"做蛋糕的公司取什麼中文名字比較好聽?\"\n",
        "\n",
        "p = llm.predict(text)\n",
        "print(p)\n",
        "print(\"===========\")\n",
        "\n",
        "p = chat_model.predict(text)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDJ8ujolFeVs",
        "outputId": "3423fff8-e0a5-41d4-f8d5-95c1fc13e55c"
      },
      "id": "TDJ8ujolFeVs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "「蛋糕時光」、「蛋糕之旅」、「糕福家庭」、「芝麻甜點」、「甜蜜樂園」、「甜心烘焙」、「甜夢工坊」、「糕點空間」。\n",
            "===========\n",
            "做蛋糕的公司取名字时，可以考虑以下几点：\n",
            "\n",
            "1. 简洁易记：选择一个简短、易记的名字，方便顾客记忆和口头传播。\n",
            "\n",
            "2. 描述性：名字最好能够反映出公司的主要业务，比如\"甜蜜蛋糕\"、\"绵绵蛋糕\"等。\n",
            "\n",
            "3. 与品牌形象相关：名字应该与公司的品牌形象相符，可以考虑使用一些与蛋糕相关的词汇，如\"烘焙\"、\"甜点\"等。\n",
            "\n",
            "4. 美感和音韵：选择一个发音优美、听起来舒适的名字，比如\"花香蛋糕\"、\"悦味坊\"等。\n",
            "\n",
            "综合考虑以上因素，以下是一些建议的公司中文名字：\n",
            "\n",
            "1. 蜜语蛋糕\n",
            "2. 蜜甜坊\n",
            "3. 烘焙天堂\n",
            "4. 糕点心语\n",
            "5. 蛋糕魔法\n",
            "6. 甜悦烘焙\n",
            "7. 美味之选\n",
            "8. 甜蜜人间\n",
            "9. 糕点乐园\n",
            "10. 爱的烘焙屋\n",
            "\n",
            "根据具体情况和个人喜好，可以选择适合自己公司形象和定位的中文名字。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<mark>**PromptTemplate** --- formatting"
      ],
      "metadata": {
        "id": "128izJ3B1rrB"
      },
      "id": "128izJ3B1rrB"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = (\n",
        "    PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "    + \", make it funny\"\n",
        "    + \"\\n\\nand in {language}\"\n",
        ")\n",
        "\n",
        "# preview of our prompt\n",
        "prompt.format(topic=\"sport\", language=\"english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "z8YJE6EVHTzO",
        "outputId": "8ef4e7be-2575-4d7d-88b6-6f317049c51d"
      },
      "id": "z8YJE6EVHTzO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a joke about sport, make it funny\\n\\nand in english'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<mark>**PromptTemplate** --- making a chain</mark>\n",
        "\n",
        "`chain = LLMChain(llm=chatmodel, prompt=prompt)`"
      ],
      "metadata": {
        "id": "uvHde8tOv0jD"
      },
      "id": "uvHde8tOv0jD"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# define llm\n",
        "chatmodel = ChatOpenAI()\n",
        "\n",
        "# define chain\n",
        "chain = LLMChain(llm=chatmodel, prompt=prompt)\n",
        "\n",
        "# run the chain\n",
        "chain.run(topic=\"food\", language=\"english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bZazyOTBGvNK",
        "outputId": "99c68dc7-c0ad-4756-c988-daad8ab233a5"
      },
      "id": "bZazyOTBGvNK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the tomato turn red? Because it saw the salad dressing!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<mark>**OutputParser**"
      ],
      "metadata": {
        "id": "9C3WXMjk1zan"
      },
      "id": "9C3WXMjk1zan"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "\"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
        "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
        "    def parse(self, text: str):\n",
        "        return text.strip().split(\", \")\n",
        "\n",
        "CommaSeparatedListOutputParser().parse(\"hi, bye, yeah\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVrokCmU11mt",
        "outputId": "4c77cbd8-40a5-486d-b975-53a83438a6a1"
      },
      "id": "jVrokCmU11mt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', 'bye', 'yeah']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<mark>**LLM + PromptTemplate + OutputParser**\n",
        "\n",
        "`chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()`"
      ],
      "metadata": {
        "id": "tN54_CXb19QC"
      },
      "id": "tN54_CXb19QC"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
        "    def parse(self, text: str):\n",
        "        return text.strip().split(\", \")\n",
        "\n",
        "# Build templates\n",
        "system_template = \"\"\"\n",
        "You are a helpful assistant who generates comma separated lists.\n",
        "A user will pass in a category, and you should generate 5 objects\n",
        "in that category in a comma separated list.\n",
        "ONLY return a comma separated list, and nothing more.\n",
        "\"\"\"\n",
        "\n",
        "human_template = \"{text}\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_template),\n",
        "    (\"human\", human_template),\n",
        "])\n",
        "\n",
        "# Build the chain\n",
        "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()"
      ],
      "metadata": {
        "id": "8hrJVzu5168Q"
      },
      "id": "8hrJVzu5168Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain\n",
        "chain.invoke( {\"text\": \"colors\"} )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHB9KzdQ2O05",
        "outputId": "e5d0b1a2-00a0-4fba-f501-1ff6ce51cf6f"
      },
      "id": "vHB9KzdQ2O05",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['red', 'blue', 'green', 'yellow', 'orange']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load from LangChain's [chainhub](https://github.com/hwchase17/langchain-hub)**"
      ],
      "metadata": {
        "id": "nzDn4uQyCPiB"
      },
      "id": "nzDn4uQyCPiB"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import load_chain\n",
        "\n",
        "chain = load_chain(\"lc://chains/llm-math/chain.json\")\n",
        "chain.run(\"whats 2 raised to .12\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "2DzzbiDeYF-0",
        "outputId": "72e89f90-6457-4a58-8aa7-8dd7e0cb8ef2"
      },
      "id": "2DzzbiDeYF-0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm_math/base.py:56: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "whats 2 raised to .12\u001b[32;1m\u001b[1;3m\n",
            "Answer: 1.0791812460476249\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: 1.0791812460476249'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save a chain**"
      ],
      "metadata": {
        "id": "U2gE3bQxCWHn"
      },
      "id": "U2gE3bQxCWHn"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0), verbose=True)\n",
        "llm_chain.save(\"llm_chain.json\")"
      ],
      "metadata": {
        "id": "KrDYXn02CYOg"
      },
      "id": "KrDYXn02CYOg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cat llm_chain.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93K5lJTPCdcH",
        "outputId": "b0b0ebe2-a092-4aef-dc8e-f7aa55a21552"
      },
      "id": "93K5lJTPCdcH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"memory\": null,\n",
            "    \"verbose\": true,\n",
            "    \"tags\": null,\n",
            "    \"metadata\": null,\n",
            "    \"prompt\": {\n",
            "        \"input_variables\": [\n",
            "            \"question\"\n",
            "        ],\n",
            "        \"input_types\": {},\n",
            "        \"output_parser\": null,\n",
            "        \"partial_variables\": {},\n",
            "        \"template\": \"Question: {question}\\n\\nAnswer: Let's think step by step.\",\n",
            "        \"template_format\": \"f-string\",\n",
            "        \"validate_template\": true,\n",
            "        \"_type\": \"prompt\"\n",
            "    },\n",
            "    \"llm\": {\n",
            "        \"model_name\": \"text-davinci-003\",\n",
            "        \"temperature\": 0.0,\n",
            "        \"max_tokens\": 256,\n",
            "        \"top_p\": 1,\n",
            "        \"frequency_penalty\": 0,\n",
            "        \"presence_penalty\": 0,\n",
            "        \"n\": 1,\n",
            "        \"request_timeout\": null,\n",
            "        \"logit_bias\": {},\n",
            "        \"_type\": \"openai\"\n",
            "    },\n",
            "    \"output_key\": \"text\",\n",
            "    \"output_parser\": {\n",
            "        \"_type\": \"default\"\n",
            "    },\n",
            "    \"return_final_only\": true,\n",
            "    \"llm_kwargs\": {},\n",
            "    \"_type\": \"llm_chain\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2️⃣ Vectorize Data to Weaviate**"
      ],
      "metadata": {
        "id": "t_Ys-kVNACur"
      },
      "id": "t_Ys-kVNACur"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "\n",
        "1. Inspect data\n",
        "2. Extract data\n",
        "3. Employ multiprocessing\n",
        "4. Initialize Vector Database (Weaviate Client)\n",
        "5. Create a schema\n",
        "6. Upload to Weaviate\n"
      ],
      "metadata": {
        "id": "kbhvXF9yQtsC"
      },
      "id": "kbhvXF9yQtsC"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install bs4 python-dotenv langchain p_tqdm tqdm aiohttp lxml openai"
      ],
      "metadata": {
        "id": "dwToHFdVPNa-"
      },
      "id": "dwToHFdVPNa-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhVg4878APPO",
        "outputId": "bb0c2d99-82a2-4e58-8aa7-73e8c3e28bd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dataclasses import dataclass, asdict\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Literal\n",
        "\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from dotenv import load_dotenv\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from p_tqdm import p_map\n",
        "import weaviate\n",
        "from weaviate.util import generate_uuid5\n",
        "\n",
        "load_dotenv(\"../../.env\", override=True)"
      ],
      "id": "QhVg4878APPO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsjv_W83APPR"
      },
      "source": [
        "### **1. Inspect data (PTT post)**"
      ],
      "id": "qsjv_W83APPR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQgff1FUAPPQ",
        "outputId": "10b04cee-79b9-4e4b-dd0d-8dda5bdc67ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of files: 100\n"
          ]
        }
      ],
      "source": [
        "# set file path\n",
        "LIMIT = 100\n",
        "ptt_files = list(Path(\"../../other_data/ptt/\").glob(\"**/*.xml\"))[:LIMIT]\n",
        "print(f\"Number of files: {len(ptt_files)}\")"
      ],
      "id": "qQgff1FUAPPQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RP_D96cAPPR",
        "outputId": "03532a5e-6f0b-4413-a255-9640591c5de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<TEI.2>\n",
            " <teiHeader>\n",
            "  <metadata name=\"media\">\n",
            "   ptt\n",
            "  </metadata>\n",
            "  <metadata name=\"author\">\n",
            "   wupaul (捷派陣線聯盟)\n",
            "  </metadata>\n",
            "  <metadata name=\"post_id\">\n",
            "   M.1617787676.A.06E\n",
            "  </metadata>\n",
            "  <metadata name=\"year\">\n",
            "   2021\n",
            "  </metadata>\n",
            "  <metadata name=\"board\">\n",
            "   HatePolitics-ptt\n",
            "  </metadata>\n",
            "  <metadata name=\"title\">\n",
            "   [公告] wupaul 違反政黑板規2-16 前科*2 水桶14天\n",
            "  </metadata>\n",
            " </teiHeader>\n",
            " <text>\n",
            "  <body author=\"wupaul (捷派陣線聯盟)\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     當事人\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"VE\">\n",
            "     判決\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     依據\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     ︰\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Neu\">\n",
            "     16\n",
            "    </w>\n",
            "    <w type=\"PERIODCATEGORY\">\n",
            "     .\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     每\n",
            "    </w>\n",
            "    <w type=\"Nf\">\n",
            "     日\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     發文\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     /\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     回文\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     上限\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     5\n",
            "    </w>\n",
            "    <w type=\"Nf\">\n",
            "     篇\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     禁止\n",
            "    </w>\n",
            "    <w type=\"A\">\n",
            "     手動\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     置\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     底\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     相似\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     文章\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     違者\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     超貼\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     文章\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     刪除\n",
            "    </w>\n",
            "    <w type=\"PERIODCATEGORY\">\n",
            "     。\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     （\n",
            "    </w>\n",
            "    <w type=\"Neqa\">\n",
            "     任何\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     原因\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     自刪\n",
            "    </w>\n",
            "    <w type=\"Caa\">\n",
            "     及\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     被\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     板主\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     刪除\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     均\n",
            "    </w>\n",
            "    <w type=\"VJ\">\n",
            "     計入\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     額度\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ）\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     證據\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     檢附\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     ︰\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Neu\">\n",
            "     634\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     8 4/07\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     R\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     [\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     新聞\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ]\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     網\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     軍頭\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     邱昱凱\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     年薪\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     350萬\n",
            "    </w>\n",
            "    <w type=\"QUESTIONCATEGORY\">\n",
            "     ？\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     柯文哲\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     ：\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     低薪\n",
            "    </w>\n",
            "    <w type=\"Da\">\n",
            "     只\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Neu\">\n",
            "     635\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     + 1 4/07\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     R\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     [\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     新聞\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ]\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     高鐵\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     設\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     偵測器\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     「\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     防\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     異物\n",
            "    </w>\n",
            "    <w type=\"VCL\">\n",
            "     侵入\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     」\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Nc\">\n",
            "     台鐵\n",
            "    </w>\n",
            "    <w type=\"VB\">\n",
            "     挨轟\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Neu\">\n",
            "     636 ~   4/07\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     □\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     [\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     討論\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ]\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     綠共仔\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     進來\n",
            "    </w>\n",
            "    <w type=\"Nd\">\n",
            "     一下\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Neu\">\n",
            "     637\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     ~   4/07\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     □\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     [\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     黑特\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ]\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     冥進棟\n",
            "    </w>\n",
            "    <w type=\"DE\">\n",
            "     的\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     改革\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Neu\">\n",
            "     638\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     4/07\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     R\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     [\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     黑特\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ]\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     冥進棟\n",
            "    </w>\n",
            "    <w type=\"DE\">\n",
            "     的\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     改革\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"FW\">\n",
            "     ●\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     639     4/07\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     R\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     [\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     黑特\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ]\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     冥進棟\n",
            "    </w>\n",
            "    <w type=\"DE\">\n",
            "     的\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     改革\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"VC\">\n",
            "     審理\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     說明\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     ︰\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     本\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     案\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     經由\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     檢舉\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     依照\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     板規\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     由\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     板主群\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     在\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     政黑\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     檢舉版\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     進行\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     討論\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"P\">\n",
            "     經\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     板主群\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     合議\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     認定\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     審議\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     結果\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     犯規\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"VE\">\n",
            "     附註\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     ︰\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"FW\">\n",
            "     #1\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     VGdvFS9\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     (\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     Hate\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     Politics\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     )\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     前科\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     * 2\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Neu\">\n",
            "     7 *\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     (\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     3-1\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     )\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     = 14\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     d\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"Neu\">\n",
            "     639\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     4/07\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     R\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     [\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     黑特\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ]\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Nb\">\n",
            "     冥進棟\n",
            "    </w>\n",
            "    <w type=\"DE\">\n",
            "     的\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     改革\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     刪除\n",
            "    </w>\n",
            "   </s>\n",
            "   <s>\n",
            "    <w type=\"VE\">\n",
            "     判決\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     結果\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     水桶\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     14\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Nc\">\n",
            "     天\n",
            "    </w>\n",
            "   </s>\n",
            "  </body>\n",
            "  <title author=\"wupaul (捷派陣線聯盟)\">\n",
            "   <s>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     [\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     公告\n",
            "    </w>\n",
            "    <w type=\"PARENTHESISCATEGORY\">\n",
            "     ]\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     wupaul\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"VJ\">\n",
            "     違反\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     政黑板規\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     2-16\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     前科\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     *2\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     水桶\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     14\n",
            "    </w>\n",
            "    <w type=\"Nf\">\n",
            "     天\n",
            "    </w>\n",
            "   </s>\n",
            "  </title>\n",
            "  <comment author=\"a0986188522\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"P\">\n",
            "     幫\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     Q\n",
            "    </w>\n",
            "    <w type=\"ETCCATEGORY\">\n",
            "     Q\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"heinse\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Nh\">\n",
            "     你\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     怎麼\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     進去\n",
            "    </w>\n",
            "    <w type=\"Di\">\n",
            "     了\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Dk\">\n",
            "     總之\n",
            "    </w>\n",
            "    <w type=\"VD\">\n",
            "     發\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     錢\n",
            "    </w>\n",
            "    <w type=\"T\">\n",
            "     啊\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"CenaWang\" c_type=\"neu\">\n",
            "   <s>\n",
            "    <w type=\"FW\">\n",
            "     https\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     //i.imgur.com/xkj\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     PYWq.jpg\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"chiguang\" c_type=\"neu\">\n",
            "   <s>\n",
            "    <w type=\"VA\">\n",
            "     明知故犯\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     刻意\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     鬧板\n",
            "    </w>\n",
            "    <w type=\"QUESTIONCATEGORY\">\n",
            "     ？\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"gowaa\" c_type=\"neu\">\n",
            "   <s>\n",
            "    <w type=\"Nh\">\n",
            "     自己\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     公告\n",
            "    </w>\n",
            "    <w type=\"Nh\">\n",
            "     自己\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     被\n",
            "    </w>\n",
            "    <w type=\"VF\">\n",
            "     罰\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Dfa\">\n",
            "     太\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     慘\n",
            "    </w>\n",
            "    <w type=\"T\">\n",
            "     了\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     ~~\n",
            "    </w>\n",
            "    <w type=\"I\">\n",
            "     嗚鳴\n",
            "    </w>\n",
            "    <w type=\"I\">\n",
            "     嗚\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     ~\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"holyhelm\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"FW\">\n",
            "     Keri\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     二\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     代\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     政黑\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     粉綠\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     怎麼\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     老是\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     選出\n",
            "    </w>\n",
            "    <w type=\"Nep\">\n",
            "     這\n",
            "    </w>\n",
            "    <w type=\"Nf\">\n",
            "     種\n",
            "    </w>\n",
            "    <w type=\"DE\">\n",
            "     的\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"mirroshadow\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"VB\">\n",
            "     罰錢\n",
            "    </w>\n",
            "    <w type=\"T\">\n",
            "     啦\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"VD\">\n",
            "     繳\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     贖罪券\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"holyhelm\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     群組仔\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     不\n",
            "    </w>\n",
            "    <w type=\"VK\">\n",
            "     意外\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     不\n",
            "    </w>\n",
            "    <w type=\"SHI\">\n",
            "     是\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     擺爛\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     就\n",
            "    </w>\n",
            "    <w type=\"SHI\">\n",
            "     是\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     鬧板\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     自\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     桶\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"miler22020\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"D\">\n",
            "     都\n",
            "    </w>\n",
            "    <w type=\"VK\">\n",
            "     怪\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     粉藍\n",
            "    </w>\n",
            "    <w type=\"Dfa\">\n",
            "     太\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     爛\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     選\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     不\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     上\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"CenaWang\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"FW\">\n",
            "     https\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     //i.imgur.com/HvKZVAa.jpg\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     白粉\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     代表\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"iamsocool\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Nep\">\n",
            "     這\n",
            "    </w>\n",
            "    <w type=\"SHI\">\n",
            "     是\n",
            "    </w>\n",
            "    <w type=\"VK\">\n",
            "     意外\n",
            "    </w>\n",
            "    <w type=\"VK\">\n",
            "     忘記\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     算\n",
            "    </w>\n",
            "    <w type=\"Caa\">\n",
            "     還是\n",
            "    </w>\n",
            "    <w type=\"VL\">\n",
            "     故意\n",
            "    </w>\n",
            "    <w type=\"QUESTIONCATEGORY\">\n",
            "     ？\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     應該\n",
            "    </w>\n",
            "    <w type=\"VG\">\n",
            "     算\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     意外\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"CenaWang\" c_type=\"neu\">\n",
            "   <s>\n",
            "    <w type=\"FW\">\n",
            "     https\n",
            "    </w>\n",
            "    <w type=\"COLONCATEGORY\">\n",
            "     :\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     //i.imgur.com/0Gttm7l.jpg\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Dfa\">\n",
            "     有夠\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     不\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     腦殘\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"mimikillua\" c_type=\"neu\">\n",
            "   <s>\n",
            "    <w type=\"VA\">\n",
            "     自導\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     自演\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     自\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     桶\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"elainakuo\" c_type=\"neu\">\n",
            "   <s>\n",
            "    <w type=\"VA\">\n",
            "     笑\n",
            "    </w>\n",
            "    <w type=\"Di\">\n",
            "     了\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"bruce2248\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"FW\">\n",
            "     QQ\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"CCfss\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"VD\">\n",
            "     發\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     錢\n",
            "    </w>\n",
            "    <w type=\"ETCCATEGORY\">\n",
            "     R\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"ralfjr\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"D\">\n",
            "     一定\n",
            "    </w>\n",
            "    <w type=\"SHI\">\n",
            "     是\n",
            "    </w>\n",
            "    <w type=\"VL\">\n",
            "     故意\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     休假\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"peterw\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"VH\">\n",
            "     了不起\n",
            "    </w>\n",
            "    <w type=\"VL\">\n",
            "     負責\n",
            "    </w>\n",
            "    <w type=\"QUESTIONCATEGORY\">\n",
            "     ？\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"yien\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Nes\">\n",
            "     某\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     ㄟ\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     取\n",
            "    </w>\n",
            "    <w type=\"SHI\">\n",
            "     是\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     在\n",
            "    </w>\n",
            "    <w type=\"P\">\n",
            "     靠\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     杯逆\n",
            "    </w>\n",
            "    <w type=\"T\">\n",
            "     啊\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     死\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     趴\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     邊緣仔\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"greedypeople\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     自\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     桶\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     還是\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     得\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     照樣\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     值班\n",
            "    </w>\n",
            "    <w type=\"T\">\n",
            "     吧\n",
            "    </w>\n",
            "    <w type=\"QUESTIONCATEGORY\">\n",
            "     ?\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"VieriKing\" c_type=\"neu\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     版主\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     不用\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     加重\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     處罰\n",
            "    </w>\n",
            "    <w type=\"T\">\n",
            "     喔\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"malisse74\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"D\">\n",
            "     沒\n",
            "    </w>\n",
            "    <w type=\"VE\">\n",
            "     看到\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     檢舉文\n",
            "    </w>\n",
            "    <w type=\"T\">\n",
            "     啊\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"a58461351\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"VH\">\n",
            "     了不起\n",
            "    </w>\n",
            "    <w type=\"COMMACATEGORY\">\n",
            "     ，\n",
            "    </w>\n",
            "    <w type=\"VL\">\n",
            "     負責\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"signorr\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"VA\">\n",
            "     休假\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     要\n",
            "    </w>\n",
            "    <w type=\"VD\">\n",
            "     給\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     錢\n",
            "    </w>\n",
            "    <w type=\"FW\">\n",
            "     ~\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"f40075566\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     巫婆\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     888888888\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"Robben\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     受虐兒\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"inhumanq\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"VD\">\n",
            "     發\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     錢\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"SiaSi\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     受虐兒\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     戰術\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     484\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"chong17\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"VH\">\n",
            "     了不起\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"VL\">\n",
            "     負責\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"s5517821\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     韓粉\n",
            "    </w>\n",
            "    <w type=\"Neu\">\n",
            "     -1\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            "  <comment author=\"slcgboy\" c_type=\"pos\">\n",
            "   <s>\n",
            "    <w type=\"Na\">\n",
            "     政黑\n",
            "    </w>\n",
            "    <w type=\"VG\">\n",
            "     自\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     桶\n",
            "    </w>\n",
            "    <w type=\"D\">\n",
            "     就\n",
            "    </w>\n",
            "    <w type=\"VH\">\n",
            "     算\n",
            "    </w>\n",
            "    <w type=\"T\">\n",
            "     了\n",
            "    </w>\n",
            "    <w type=\"WHITESPACE\">\n",
            "    </w>\n",
            "    <w type=\"Cbb\">\n",
            "     但是\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     政檢\n",
            "    </w>\n",
            "    <w type=\"VD\">\n",
            "     給\n",
            "    </w>\n",
            "    <w type=\"Nh\">\n",
            "     我\n",
            "    </w>\n",
            "    <w type=\"VA\">\n",
            "     回來\n",
            "    </w>\n",
            "    <w type=\"VC\">\n",
            "     處理\n",
            "    </w>\n",
            "    <w type=\"Na\">\n",
            "     事情\n",
            "    </w>\n",
            "   </s>\n",
            "  </comment>\n",
            " </text>\n",
            "</TEI.2>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# inspect 1 post\n",
        "with ptt_files[7].open() as f:\n",
        "    soup = bs(f.read(), \"xml\")\n",
        "print(soup.prettify())"
      ],
      "id": "6RP_D96cAPPR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQd4LA3OAPPS"
      },
      "source": [
        "### **2. Extract data**\n",
        "\n",
        "- https://realpython.com/python-data-classes/    \n",
        "- https://realpython.com/python-type-checking/"
      ],
      "id": "PQd4LA3OAPPS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq7WrIoyAPPS"
      },
      "outputs": [],
      "source": [
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "SPLITTER = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=8000, chunk_overlap=0\n",
        ")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ContentItem:\n",
        "    media: Literal[\"ptt\"]     # media source of the post or comment\n",
        "    content_type: Literal[\"post\", \"comment\"]  # post or comment\n",
        "    author: str               # author of the post or comment\n",
        "    post_id: str              # id of the post (comments share id with the post)\n",
        "    year: str                 # year of the post\n",
        "    board: str                # board of the post (NTU-ptt, gossiping, etc.)\n",
        "    title: str                # title of the post\n",
        "    text: str                 # text of the post or comment\n",
        "    rating: Literal[ \"pos\", \"neu\", \"neg\", \"\"]  # rating of the comment (positive, neutral, negative)\n",
        "    order: int                # 0 for post, 1, 2, 3, ... for comments\n",
        "    chunk: int                # if text too long, split into chunks\n",
        "    total_chunks: int         # total number of chunks\n",
        "\n",
        "\n",
        "\n",
        "def get_comments(parent: ContentItem, soup: bs) -> list[ContentItem]:\n",
        "    \"\"\"\n",
        "    Get comments from a post.\n",
        "\n",
        "    Args:\n",
        "        parent: ContentItem object of the post\n",
        "        soup: BeautifulSoup object of the post\n",
        "\n",
        "    Returns:\n",
        "        List of ContentItem objects\n",
        "    \"\"\"\n",
        "    res = []\n",
        "    comments = soup.find_all(\"comment\")\n",
        "    content_type = \"comment\"\n",
        "\n",
        "    for comment_idx, comment in enumerate(comments, 1):\n",
        "        author = comment[\"author\"]\n",
        "        rating = comment[\"c_type\"]\n",
        "        text = comment.get_text().replace(\"\\n\", \"\")\n",
        "        chunks = SPLITTER.split_text(text)\n",
        "        if not chunks:\n",
        "            chunks = [\"\"]\n",
        "        for chunk_idx, chunk in enumerate(chunks, 1):\n",
        "            res.append(\n",
        "                ContentItem(\n",
        "                    media=parent.media,\n",
        "                    content_type=content_type,\n",
        "                    post_id=parent.post_id,\n",
        "                    author=author,\n",
        "                    rating=rating,\n",
        "                    text=chunk,\n",
        "                    year=parent.year,\n",
        "                    board=parent.board,\n",
        "                    title=parent.title,\n",
        "                    order=comment_idx,  # 0 for post, 1, 2, 3, ... for comments\n",
        "                    chunk=chunk_idx,\n",
        "                    total_chunks=len(chunks),\n",
        "                )\n",
        "            )\n",
        "    return res\n",
        "\n",
        "\n",
        "def get_post_info(path: Path) -> list[ContentItem]:\n",
        "    \"\"\"\n",
        "    Get post information from a post\n",
        "\n",
        "    Args:\n",
        "        path: path to the post\n",
        "\n",
        "    Returns:\n",
        "        List of ContentItem objects\n",
        "    \"\"\"\n",
        "    content_type = \"post\"\n",
        "\n",
        "    with path.open() as f:\n",
        "        soup = bs(f.read(), \"xml\")\n",
        "\n",
        "    media = soup.find(\"metadata\", attrs={\"name\": \"media\"}).get_text().replace(\"\\n\", \"\")\n",
        "    author = (\n",
        "        soup.find(\"metadata\", attrs={\"name\": \"author\"}).get_text().replace(\"\\n\", \"\")\n",
        "    )\n",
        "    post_id = (\n",
        "        soup.find(\"metadata\", attrs={\"name\": \"post_id\"}).get_text().replace(\"\\n\", \"\")\n",
        "    )\n",
        "    year = soup.find(\"metadata\", attrs={\"name\": \"year\"}).get_text().replace(\"\\n\", \"\")\n",
        "    board = soup.find(\"metadata\", attrs={\"name\": \"board\"}).get_text().replace(\"\\n\", \"\")\n",
        "    title = soup.find(\"metadata\", attrs={\"name\": \"title\"}).get_text().replace(\"\\n\", \"\")\n",
        "    text = soup.find(\"body\").get_text().replace(\"\\n\", \"\")\n",
        "    chunks = SPLITTER.split_text(text)\n",
        "    if not chunks:\n",
        "        chunks = [\"\"]\n",
        "\n",
        "    posts = []\n",
        "    for idx, chunk in enumerate(chunks, 1):\n",
        "        posts.append(\n",
        "            ContentItem(\n",
        "                media=media,\n",
        "                author=author,\n",
        "                post_id=post_id,\n",
        "                year=year,\n",
        "                board=board,\n",
        "                title=title,\n",
        "                text=chunk,\n",
        "                rating=\"\",\n",
        "                content_type=content_type,\n",
        "                order=0,  # 0 for post, 1, 2, 3, ... for comments\n",
        "                chunk=idx,\n",
        "                total_chunks=len(chunks),\n",
        "            )\n",
        "        )\n",
        "    if not posts:\n",
        "        print(f\"Empty post: {path}\")\n",
        "        raise ValueError(path)  # shouldn't happen\n",
        "\n",
        "    comments = get_comments(posts[0], soup)\n",
        "\n",
        "    return posts + comments\n",
        "\n",
        "\n",
        "def dedupe(items: list[ContentItem]) -> list[ContentItem]:\n",
        "    \"\"\"\n",
        "    Dedupe items\n",
        "\n",
        "    Args:\n",
        "        items: list of ContentItem objects\n",
        "\n",
        "    Returns:\n",
        "        List of ContentItem objects\n",
        "    \"\"\"\n",
        "    res = []\n",
        "    seen = set()\n",
        "    for item in items:\n",
        "        dumps = json.dumps(asdict(item))  # strings are hashable\n",
        "        if dumps not in seen:\n",
        "            seen.add(dumps)\n",
        "            res.append(item)\n",
        "    return res"
      ],
      "id": "aq7WrIoyAPPS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYalAEb3APPT"
      },
      "source": [
        "### **3. Employ multiprocessing**\n",
        "\n",
        "- Use multiprocessing when you are CPU-bound\n",
        "\n",
        "- More info: https://realpython.com/python-concurrency/#multiprocessing-version"
      ],
      "id": "BYalAEb3APPT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7b2c155770534e6abb9bf6846ed9ed43"
          ]
        },
        "id": "wN-BRm2eAPPT",
        "outputId": "15fc5a5e-b840-4d70-f06e-6011b1f6f81e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2c155770534e6abb9bf6846ed9ed43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of posts/comments: 2577\n"
          ]
        }
      ],
      "source": [
        "res = p_map(get_post_info, ptt_files)  # default uses all cores\n",
        "res = dedupe([item for sublist in res for item in sublist])  # flatten list of lists\n",
        "\n",
        "print(f\"Number of posts/comments: {len(res)}\")"
      ],
      "id": "wN-BRm2eAPPT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7-Ov28aAPPU"
      },
      "source": [
        "### **4. Initialize vector database**\n",
        "\n",
        "- The vector database is `Weaviate.Client`.\n",
        "- The `url` refers to your IP/url (if self-hosted). See also: [Weaviate installation](https://weaviate.io/developers/weaviate/installation)\n",
        "\n",
        "- You can also use services provided by Weaviate. See also: [Weaviate products](https://weaviate.io/products)"
      ],
      "id": "e7-Ov28aAPPU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FboLSAUYAPPU"
      },
      "outputs": [],
      "source": [
        "client = weaviate.Client(\n",
        "    url=os.environ[\"WEAVIATE_URL\"],\n",
        "    auth_client_secret=weaviate.AuthApiKey(api_key=os.environ[\"WEAVIATE_ADMIN_PASS\"]),\n",
        "    timeout_config=(5, 30),  # (connect timeout, read timeout) # type: ignore\n",
        "    additional_headers={\"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"]},\n",
        ")"
      ],
      "id": "FboLSAUYAPPU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BElYw_Y8APPU"
      },
      "source": [
        "### **5. Create a schema**\n",
        "\n",
        "- Each Weaviate class requires a `schema` that defines the data structure in a formal language.\n",
        "  \n",
        "- `schema` is a blueprint of how the data is to be organized and stored; it defines:\n",
        "  - data classes (i.e., collections of objects),\n",
        "  \n",
        "  - properties within each class (e.g., name, type, description, settings),\n",
        "  \n",
        "  - possible graph links between data objects (cross-references),\n",
        "  \n",
        "  - the vectorizer module (if any) to be used for the class,\n",
        "  \n",
        "  - settings such as the `vectorizer module` and index configurations.\n",
        "\n",
        "\n",
        "- More info: https://weaviate.io/developers/weaviate/tutorials/schema"
      ],
      "id": "BElYw_Y8APPU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTT post's metadata\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1jKkLx0Bw6cl9SrDtaMbMV83rD-PJNHpu\" width=\"500px\">"
      ],
      "metadata": {
        "id": "V5VFk644LQwj"
      },
      "id": "V5VFk644LQwj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phfhiqAkAPPU"
      },
      "outputs": [],
      "source": [
        "# The schema for our content items (PTT posts/comments)\n",
        "\n",
        "schema = {\n",
        "    \"class\": \"TestContentItem\",\n",
        "    \"description\": \"General content item\",\n",
        "    # We require Weaviate to call OpenAI to vectorize the raw data\n",
        "    \"moduleConfig\": {\"text2vec-openai\": {\"vectorizeClassName\": False}},\n",
        "    \"vectorizer\": \"text2vec-openai\",\n",
        "    \"properties\": [\n",
        "        {\n",
        "            \"name\": \"media\",\n",
        "            \"description\": \"Source of the content\", # For us\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": True,}\n",
        "                    # So the model won't vectorize the \"media,\"\n",
        "                    # the raw text will still be uploaded to Weviate\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"content_type\",\n",
        "            \"description\": \"Type of the content\",\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": True,\n",
        "                    # So the model won't vectorize \"content_type\" (Same as \"media\")\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"author\",\n",
        "            \"description\": \"Author of the content\",\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"post_id\",\n",
        "            \"description\": \"Post id of the content\",\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"year\",\n",
        "            \"description\": \"Year of the content\",\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"board\",\n",
        "            \"description\": \"Board of the content\",\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": False,\n",
        "                    \"vectorizePropertyName\": True,\n",
        "                    # So the model WILL vectorize \"board\"\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"title\",\n",
        "            \"description\": \"Title of the content\",\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": False,\n",
        "                    \"vectorizePropertyName\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"text\",\n",
        "            \"description\": \"Text of the content\",\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": False,\n",
        "                    \"vectorizePropertyName\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"rating\",\n",
        "            \"description\": \"Rating of the content\",\n",
        "            \"dataType\": [\"text\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": False,\n",
        "                    \"vectorizePropertyName\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"order\",\n",
        "            \"description\": \"0 for post, 1, 2, 3, ... for comments\",\n",
        "            \"dataType\": [\"int\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"chunk\",\n",
        "            \"description\": \"Chunk of the current content\",\n",
        "            \"dataType\": [\"int\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"total_chunks\",\n",
        "            \"description\": \"Total chunks of the content\",\n",
        "            \"dataType\": [\"int\"],\n",
        "            \"moduleConfig\": {\n",
        "                \"text2vec-openai\": {\n",
        "                    \"skip\": True,\n",
        "                }\n",
        "            },\n",
        "        },\n",
        "    ],\n",
        "}"
      ],
      "id": "phfhiqAkAPPU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR1-JauCAPPV"
      },
      "outputs": [],
      "source": [
        "client.schema.create_class(schema)"
      ],
      "id": "kR1-JauCAPPV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOlzr_8iAPPV"
      },
      "source": [
        "### **6. Upload to Weaviate**\n",
        "\n",
        "The code below will automatically generate a vector for each item using the `vectorizer` specified in the schema."
      ],
      "id": "kOlzr_8iAPPV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW2at1X5APPV"
      },
      "outputs": [],
      "source": [
        "client.batch.configure(\n",
        "    num_workers=16,\n",
        "    batch_size=100,\n",
        "    dynamic=True,\n",
        ")\n",
        "with client.batch as batch:\n",
        "    for item in res:\n",
        "        batch.add_data_object(\n",
        "            data_object=asdict(item),\n",
        "            class_name=\"TestContentItem\",\n",
        "            uuid=generate_uuid5(asdict(item)),\n",
        "        )"
      ],
      "id": "DW2at1X5APPV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp0bYeszCsoC"
      },
      "source": [
        "**Check: Use weaviate-client to query Weaviate**"
      ],
      "id": "Dp0bYeszCsoC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZkM4JhTCsoC",
        "outputId": "a6e925f5-d6c5-48ef-d905-bd967b90b5b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_additional: {'vector': [-0.012226269, -0.01181336, 0.002815121, -0.033452526, -0.020701375, -0.01902175, -0.0187978, -0.0018160943, -0.008167176, -0.01450076, 0.016320353, -0.0035779506, -0.014402782, 0.014073855, -0.0029218472, 0.010336691, 0.011169504, 0.01373793, 0.0013524478, -0.005290818, -0.0053713, -0.0073553566, -0.038015507, 0.021765137, -0.0018633336, 0.0002869359, 0.015354569, -0.007649291, -0.019441657, -0.011141511, 0.014297806, -0.011169504, -0.013269035, -0.0017294886, -0.0109805465, -0.0009237936, 0.009566862, 0.016936217, 0.0059381733, 0.0003282704, 0.008398123, -0.010028759, 0.017790025, 0.0085031, -0.0088110315, 0.009839801, 0.025670264, -0.03496419, 0.00505637, 0.024228586, 0.007908233, 0.026818007, -0.009916784, -0.0017067436, 0.0021362726, 0.010441667, 0.0117013855, 0.009741823, -0.011498431, -0.003208783, 0.017552078, -0.006477053, -0.031269014, 0.005903181, -0.005826198, -0.014038864, -0.02582423, 0.005259325, -0.009244935, 0.0014897921, 0.029421426, 0.028651599, 0.022367002, -0.015452547, 0.056855295, -0.03767958, -0.026734026, 0.0022972368, -0.019903554, 0.02112128, 0.032416757, -0.011344465, -0.0008516222, 0.004860414, 0.019119728, 0.0051438506, -0.024284573, 0.036531836, -0.021597175, -0.011820359, -0.0005240079, 0.018769806, 0.0134160025, 0.013520979, 0.0020732868, 0.032696694, -0.03370447, 0.028973525, 0.0036356878, -0.036587823, 0.029701363, -0.018545857, -0.02975735, -0.014269812, -0.020155497, 0.008356133, 0.0060186554, -0.007936227, 0.011253485, 0.007152402, -0.029085502, 0.017440103, 0.017776027, -0.008314142, -0.031800896, -0.011372459, 0.011981323, -0.006144627, -0.0420746, -0.028091723, 0.022870889, 0.00068628415, 0.019847564, -0.0017583572, 0.024228586, -0.0019840568, -0.0053992937, -0.0022010081, 0.009734825, 0.0009859047, 0.019889556, -0.0026331616, 0.016586294, 0.012793141, -0.027629826, 0.009825804, 0.0026121663, -0.010455664, -0.028973525, -0.010994543, 0.01928769, 0.02403263, -0.003688176, -0.006543538, 0.02063139, 0.0074533345, 0.0053083138, 0.029701363, -0.007796258, 0.00091592036, 0.0021992587, -0.005255826, 0.00554976, 0.011078524, -0.015690494, 0.02040744, -0.0061166333, 0.005304815, -0.0043495283, -0.027811786, -0.008006211, 0.0038596375, 0.01275815, 0.004202561, 0.02121926, 0.04171068, -0.0044999947, 0.018965762, 0.0308771, -0.0017863509, 0.011911338, 0.00872705, -0.023122834, 0.027601833, 0.030625157, 0.029813338, 0.0024249582, -0.0073833503, -0.0040031057, -0.009405898, -0.04423012, 0.0046224673, 0.0053957943, 0.039107263, 0.007957222, -0.019609619, 0.013800916, -0.011183501, 0.004853416, -0.0098468, 0.029645376, 0.01902175, -0.013388009, -0.0066940044, -0.5912279, -0.016922219, -0.0020995308, 0.041570712, 0.007222386, 0.0045139915, 0.022101061, 0.012954106, -0.03683977, -0.007747269, 0.008202167, 0.014129843, 0.018923772, -0.00031099303, 0.009300922, -0.019721594, 0.0025421819, 0.011078524, 0.020659383, 0.0058926833, -0.01991755, 0.020981312, -0.010798587, 0.018923772, 0.020323459, 0.0111555075, 0.014346794, -0.00487791, -0.012835132, 0.020785356, -0.029645376, 0.018657831, -0.022143053, 0.0015737733, 0.06785684, -0.008734048, -0.031660926, 0.0038806328, 0.004237553, 0.014934663, -0.03258472, -0.016222375, 0.018643834, -0.024228586, -0.011764372, 0.0013848156, 0.018559853, 0.0007492701, 0.007208389, -0.008895013, -0.005017879, 0.009293923, 0.0076282956, 0.025222365, -0.0077122767, -0.005164846, -0.006638017, -0.041514724, -0.0033487517, 0.015900448, 0.0036531838, 0.0028308674, -0.0016735011, -0.023514746, -0.016096404, -0.0059276754, -0.04949294, 0.02268893, 0.01347199, -0.0061831186, -0.009286925, 0.0045629805, -0.0119743245, -0.0001267373, 0.013227045, 0.013800916, 0.022800906, -0.0375956, -0.016978206, 0.022632943, -0.014752704, -0.0009334164, -0.02586622, 0.0031055561, 0.012394231, -0.0047519384, -0.016208379, 0.021009305, 0.008321141, 0.0058646896, 0.0246205, 0.018895779, 0.013094074, 0.0051403516, -0.017985981, 0.018713819, 0.006050148, -0.02600619, 0.0040555936, -0.014157836, -0.007187394, -0.020337455, 0.002662905, -0.0021117781, 0.0008297521, 0.012660171, -0.02219904, -0.02832967, 0.033088606, -0.009615852, 0.011253485, -0.008776039, -0.0024756968, -0.0058296975, -0.02362672, -0.025320342, 0.008090192, 0.007810255, -0.012380234, 0.012982099, 0.0148646785, 0.01910573, 0.018937768, -0.014227821, -0.00025522424, 0.04042297, 0.0025946703, -0.021359228, 0.0052978164, 0.0061341296, -0.002622664, 0.004363525, 0.040758893, -0.017915998, 0.04143074, 0.0036986736, 0.027671818, -0.013213048, 0.014101849, -0.0036706799, -0.017034194, 0.011127514, 0.0053643016, -0.016446326, -0.0042445515, -0.030905094, -0.0028396156, -0.007411344, 0.004534987, 0.02541832, -0.020253474, 0.0033540006, 0.006641516, 0.002528185, -0.008832026, -0.0029253464, 0.020393444, -0.018279916, 7.333322e-06, -0.008678061, -0.007425341, -0.00013592276, -0.009146956, -0.012506206, -0.014612735, 0.00019836193, 0.013353016, -0.00599766, -0.012429222, -0.007397347, 0.004783431, 0.0001154742, 0.002599919, -0.0010611379, -0.025278352, 0.023752693, -0.011820359, -0.028917538, -0.020197487, 0.00362519, -0.0031073056, 0.0033627485, -0.023178821, -0.0057457164, 0.0013988124, 0.012520202, -0.01688023, 0.02747586, -0.029085502, -0.00027512602, -0.014612735, 0.021233255, 0.0016463822, -0.0020977813, 0.020743364, 0.028567618, 0.024788462, -0.0074673314, 0.032836664, 0.030849107, 0.0066975034, -0.0071104113, -0.011302475, -0.008804033, -0.0015589016, -0.023206815, -0.00074533344, -0.014892672, 0.03902328, 0.029869325, 0.0021590176, -0.026664043, -0.011302475, -0.0007488327, -0.01539656, -0.0022709926, -0.034572273, -0.0022255026, 0.0051543484, -0.0039961073, 0.00863607, -0.00640007, 0.011295476, 0.024998415, -0.009048978, -0.015466544, 0.01812595, 0.009510875, 0.024354558, -0.009734825, -0.016670275, -0.00053056894, 0.010322694, 0.019035747, -0.0026156656, -0.04403416, 0.025810232, -0.0033907425, 0.039107263, 0.009335914, -0.009153955, 0.009797811, 0.016810244, -0.008454111, -0.0052068364, -0.004461503, 0.042326543, 0.011925335, -0.02264694, 0.010266706, -0.009748822, 0.005007381, -0.020547409, 0.011267482, 0.035076164, -0.0070824176, -0.00465396, 0.022716925, 0.023962647, 0.017258143, 0.0029200974, 0.0005931175, -0.004926899, -0.002717143, 0.009279926, -0.009048978, 0.0020470426, -0.042494506, -0.008328139, 0.0045629805, -0.0025211866, -0.007866242, 0.023332786, -0.007008934, 0.010098743, -0.011169504, 0.0009237936, -0.0066695097, 0.013360015, -0.0105256485, -0.005199838, -0.024760468, 0.012464215, 0.048905075, -0.017216153, -0.01494866, -0.013450994, -0.007187394, -0.02627213, -0.0031440475, -0.013052084, 0.0057492154, -0.0006985314, 0.0025211866, -0.01588645, -0.020645387, 0.0109735485, -0.0017950989, -0.027335892, 0.0052208337, 0.006015156, 0.015816467, -0.0143188005, -0.022450984, 0.0085031, 0.00854509, -0.013192052, -0.018265918, -0.0019928047, 0.0057177222, -0.009909785, -0.012037311, -0.0016026419, -0.0039471183, -0.02470448, 0.030009294, -0.011659395, -0.026328117, 0.022520969, -0.01226126, -0.01741211, 0.008160177, -0.016740259, -0.014290807, 0.10777592, 0.048373193, 0.019007754, 0.018027972, -0.036083937, 0.025880218, -0.034572273, -0.016936217, -0.004510492, -0.0187978, 0.0044475063, 0.0035149646, 0.012842131, -0.0026996469, 0.032080833, -0.008573084, 0.02362672, -0.003576201, 0.033060614, 0.02242299, -0.0052838195, -0.019259697, 0.021107284, 0.039079268, -0.016040416, -0.0089859925, 0.014962656, 0.020015528, -0.01060963, -0.005966167, -0.034292337, -0.02022548, 0.013492985, -0.009951777, -0.009216941, 0.01150543, 0.021457206, 0.006466555, 0.0069179544, -0.0018755809, 0.007292371, 0.046105698, 0.0056862296, -0.012282256, 0.004157071, 0.016950212, 0.012856128, 0.008776039, 0.003915625, -0.02716793, 0.029953307, 0.013625955, -0.030037288, -0.014171833, 0.012954106, -0.0024354558, -0.03454428, 0.0014801692, 0.01951164, 0.0013367013, -0.02273092, -0.043362312, 0.0047099474, -0.01861584, -0.023290796, -0.016670275, -0.014115846, -0.024900436, 0.009762819, -0.008692058, -0.004618968, -0.008608077, -0.0040800883, -0.005136852, 0.0057037254, -0.00075670594, 0.018153943, -0.0023339784, -0.002823869, 0.006463056, -0.0045769773, -0.02814771, -0.026426096, -0.020505419, 0.013339019, 0.013052084, 0.021681156, 0.010469661, -0.014892672, -0.0063615786, 0.011183501, -0.0033907425, 0.005679231, 0.003674179, -0.004143074, 0.002332229, 0.018265918, 0.016978206, -0.008405122, 0.005934674, -0.0018003477, -0.033004627, -0.019721594, 0.016950212, 0.02291288, 0.0075793066, 0.0072713755, 0.013940885, 0.008433116, -0.0069879387, 0.023514746, -0.02466249, -0.010868572, 0.006036151, 0.0072433813, 0.017314132, 0.009790813, 0.021009305, -0.00255093, 0.00032258418, -0.012989098, -0.00854509, 0.005868189, 0.01427681, -0.0331166, -0.0053328085, -0.038967293, -0.027321896, 0.0061131343, -0.008608077, 0.007516321, 0.008286148, -0.00013023653, -0.006452558, -0.025628274, 0.009825804, -0.0054762764, 0.0028378658, 0.019581625, 0.0011643649, -0.025068399, -0.016404334, -0.0005038874, -0.02250697, 0.047113474, -0.025628274, -0.023066847, -0.0034747235, 0.006652014, 0.007866242, 0.0023024855, 0.0065540355, -0.011295476, 0.014150838, 0.017216153, -0.04761736, -0.012583189, -0.033144593, 0.016544303, 0.019707596, 0.02197509, -0.009909785, 0.000653479, 0.011953329, 0.0035692025, 0.005161347, -0.016936217, -0.022269024, -0.027377883, -0.0017679799, 0.01606841, 0.009342913, -0.008671063, -0.012856128, 0.00043434044, 0.0063860733, -0.00035189014, 0.030737132, -0.016236372, -0.033536505, 0.012373235, -0.021387221, -0.008999989, -0.01647432, -0.02385067, -0.00053406815, 8.276471e-06, 0.011792365, 0.0047659352, 0.012499208, -0.0041150805, -0.03857538, 0.007173397, -0.016390339, 0.033956412, 0.016726263, -0.016446326, 0.0012623429, 0.010987545, 0.030625157, 0.03213682, 0.014556748, -0.00859408, 0.0018720817, -0.004108082, 0.010945554, -0.03272469, -0.013884897, -0.01709018, -0.039667137, -0.012961104, -0.0097138295, -0.0076282956, -0.035915975, 0.017202156, -0.0032455248, -0.017048191, 0.0031073056, -0.013220046, -0.015466544, -0.0034939693, -0.0008109438, 0.029197477, -0.0071943924, 0.021583177, 0.050808646, 0.019707596, -0.012870125, -0.04199062, -0.015088629, -0.005021378, 0.016152391, 0.03865936, -0.015774475, 0.0055217664, 0.015564523, 0.025894213, -0.010098743, -0.026216142, 0.012555195, -0.00966484, 0.014780697, 0.0049234, -0.027783792, -0.011204497, 0.0058646896, -0.017384116, -0.008048202, -0.026650045, -0.0038736344, 0.010077748, 0.0005804328, -0.0153125785, 0.0065995255, 0.017902, -0.020939322, -0.004363525, -0.019483646, -0.018195935, 0.032528732, -0.015088629, 0.027573839, -0.018811796, 0.009160953, -0.0034694748, 0.006193616, -0.004926899, -0.016978206, -0.026244136, 0.045853756, -0.025082396, -0.006770987, 0.007537316, 0.009034981, 0.023962647, -0.013709936, -0.005185841, -0.023710702, -0.024690483, 0.009678838, 0.011624402, 0.019777581, -0.024424542, -0.010553642, -0.0053013153, -0.0075303176, -0.00089929905, -0.02702796, 0.026566064, -0.015284585, -0.030989075, 0.0013856904, -0.02170915, -0.003513215, -0.0061691217, -0.00496889, 0.012044309, 0.04260648, -0.030261239, 0.006963444, -0.026510077, -0.00018130324, -0.032108825, -0.011071526, -0.0025649269, -0.031940863, 0.022968868, -0.041122813, -0.01857385, -0.024788462, -0.011330469, 0.018293912, 0.007348358, 0.0101687275, 0.042662468, -0.0074533345, 0.0054867743, -0.010315695, -0.013101073, 0.021667158, -0.010819582, -0.0043145358, -0.0025299347, -0.026887992, 0.018223928, -0.015732484, 0.015858456, -0.002260495, -0.030737132, -0.027713807, 0.03238876, 0.02018349, -0.016348347, -0.031129045, -0.04019902, -0.016278362, -0.017538082, 0.025082396, -0.02967337, 0.0030390709, 0.036671806, 0.005903181, 0.0053328085, 0.0026978971, 0.013996872, -0.011792365, 0.00993778, -0.019903554, 0.00277488, -0.023976643, -0.016096404, 0.02179313, 0.0023042352, -0.017510088, -0.0022989863, 0.014297806, -0.039107263, -0.023682708, 0.008223163, 0.033312555, 0.045993723, -0.013353016, 0.017062187, 0.015326575, 0.010952553, 0.016404334, -0.00657853, -0.024984417, -0.0115194265, -0.035831995, -0.0066695097, 0.016348347, -0.018293912, 0.01060963, 0.021359228, 0.021107284, 0.013339019, 0.026748024, -0.00095791096, -0.008762042, -0.031716913, 0.004569979, -0.0069914376, -0.0027643824, 0.0049478943, -0.02121926, -0.0048464173, 0.011799363, -0.004807926, -0.033508513, 0.007516321, -7.3210205e-05, 0.0012448468, 0.020505419, -0.0061691217, -0.01647432, 0.0028973527, -0.02081335, 0.024886439, 0.019357676, -0.007495325, 0.003142298, 0.001396188, -0.010770594, -0.021681156, -0.0035079662, -0.041374754, -0.020169493, 0.02474647, -0.009706832, 0.005164846, 0.015046638, 0.010938556, -0.004381021, -0.009069974, -0.002984833, 0.009216941, -0.024284573, 0.027713807, -0.002183512, -0.03513215, -0.037483625, -0.01629236, -0.0057352185, -0.004192063, -0.01848987, -0.0053713, -0.015116623, 0.009706832, -0.00018031908, 0.0047869305, -0.024466533, 0.011666393, 0.00886002, -0.011848353, 0.013129067, 0.27590635, -0.012940109, 0.031856883, 0.026412098, 0.014388785, 0.007901235, 0.007411344, 0.015088629, -0.005857691, -0.0009439141, -0.011960328, 0.003280517, -0.0056022485, -0.006561034, -0.008999989, -0.04506993, -0.047813315, -0.031017069, -0.018363897, -0.033312555, 0.0076912814, 0.010959552, -0.01141445, -0.012331245, 0.018279916, -0.015298582, -0.015970431, -0.033256568, 0.007537316, -0.0035429583, -0.025894213, -0.02421459, -0.004346029, -0.004797428, -0.014738707, -0.00054281624, 0.010308697, -0.031129045, 0.021149274, 0.004094085, -0.0037721572, -0.0014880425, 0.010924559, -0.004283043, -0.017971985, 0.011113517, -0.010994543, 0.009853798, 0.0006202364, 0.017818019, -0.023976643, -0.0079922145, 0.04322234, 0.015284585, -0.01154742, -0.00045533577, 0.009874794, 0.0034922196, -0.019091735, 0.0066170213, 0.011624402, 0.041738674, -0.009321917, 0.02975735, -0.025194371, 0.012380234, -0.024536518, -0.007943225, -0.002645409, -0.009251933, -0.009286925, -0.008307144, -0.017398113, 0.0017907249, -0.041010838, -0.02631412, 0.02089733, 0.029057508, 0.026440091, 0.010679614, -0.026062177, -0.005588251, 0.017622063, -0.0046469616, 0.009125961, -0.048625134, 0.030513182, 0.021233255, -0.0027958753, 0.0112464875, 0.0064420607, -0.016166387, -0.01494866, 0.014570745, -0.011351463, 0.013786919, 0.005483275, 0.01637634, -0.027825782, 0.014458769, -0.025012411, 0.057667114, 0.030597163, 0.0014189329, -0.027041959, -0.013429999, 0.016656278, 0.0062950933, 0.0021152773, -0.011176502, -0.026398102, -0.047365416, 0.003915625, 0.010665617, 0.019133724, -0.009881792, 0.013905893, -0.007747269, -0.0032472746, 0.0020033023, 0.00090279826, -0.038071495, -0.0027241413, -0.011148509, -0.0011687388, -0.016712265, -0.003768658, 0.004213059, 0.00030705638, -0.037091713, 0.03474024, -0.00778926, -0.00013526666, -0.01517261, -0.015900448, 0.0062810965, -0.000930792, -0.016894225, 0.0030495685, 0.00595217, -0.0017539831, 0.0068864613, 0.013423, 0.0012658421, 0.032024845, 0.0024861945, 0.017468097, -0.0045279884, 0.02112128, -0.011568415, -0.033368543, -0.0045944736, 0.0057352185, -0.009419895, 0.02523636, -0.007106912, -0.045321874, -0.033900425, -0.004188564, 0.005196339, -0.051004604, -0.010343689, 0.036447857, -0.041094817, -0.019763583, -0.0005896183, -0.1803917, 0.007866242, 0.02824569, -0.004807926, 0.014255814, 0.0070509245, 0.012464215, 0.013989874, -0.0052068364, -0.0018475872, 0.01270916, 0.011736378, -0.0078172535, 0.007838248, -0.011281479, -0.0023392274, -0.02855362, 0.008964997, 0.0071943924, -0.011582412, 0.037063718, 0.003919124, -0.0025369332, 0.016208379, 0.008398123, 0.0055112685, -0.024606502, 0.031800896, 0.016026419, -0.019427659, -0.021051297, -0.00015177859, 0.0109805465, 0.004828921, 0.025222365, -0.0018598344, -0.007509322, -0.027153933, 0.012009317, 0.02975735, 0.019399665, 0.027195923, 0.0063965707, 2.1514725e-05, -0.025026409, 0.033228576, -0.003943619, 0.0056267427, 0.0072293845, -0.0033644983, 0.0040206015, -0.018657831, 0.03877134, 0.01051865, 0.019623615, 0.0034117377, -0.000406128, -0.012205273, 0.0055112685, 0.030289233, -0.030205252, -0.0008310643, -0.008328139, 0.004685453, -0.0049513937, -0.027265908, -0.011596409, 0.01812595, -0.00514735, -0.002403963, -0.023304792, -0.029057508, 0.01727214, -0.022548962, 0.037567604, -0.0026751524, -0.020379446, 0.014794694, 0.018923772, 0.028343666, -0.0017679799, 0.05567956, 0.0073833503, 0.000114052644, 0.00062854704, 0.013989874, -0.0048674126, 0.005161347, -0.005185841, -0.02523636, 0.014073855, -0.0064455597, -0.0041500726, -0.009909785, 0.0035709522, 0.012107295, 0.016096404, 0.024732474, -0.01472471, -0.01096655, 0.011960328, -0.00052838196, -0.03236077, 0.0117013855, 0.0036146923, 0.005350305, 0.013395007, 0.03079312, 0.03280867, -0.0022814902, -0.001154742, 0.023948649, 0.021877112, 0.022520969, 0.042410523, 0.018853787, -0.016306357, -0.025432317, 0.01056064, -0.0058996817, -0.0062636007, -0.008797035, -0.0041115815, 0.027181927, -0.003486971, 0.0020470426, -0.0720559, -0.027307898, 0.031436976, 0.03857538, -0.022171047, 0.017426107, 0.027573839, 0.0076142987, -0.0051928395, 0.031576946, 0.002645409, -0.028189702, -0.014472766, 0.0073833503, 0.028091723, -0.0012273508, 0.009314919, -0.015284585, 0.023234809, 0.04439808, -0.012450218, -0.019413663, -0.0012019814, -0.0023077345, -0.002739888, -0.0039821104, -0.016348347, 0.035915975, 0.0344603, 0.035244126, -0.0047274437, 0.0063930717, -0.006910956, -0.0011040033, -0.00012531575, -0.015634507, -0.022590952, -0.029365439, 0.013814913, -0.032052837, 0.001713742, 0.0006574156, 0.01065162, -0.0005336308, -0.01928769, -0.02170915, -0.0004890157, 0.037315663, 0.020043522, -0.014542751, -0.017440103, -0.02134523, -0.0043495283, -0.0041500726, -0.0012535949, -0.006914455, 0.015830463, 0.025208367, -0.014962656, 0.011638399, -0.01150543, 0.01351398, -0.0124222245, 0.006781485, 0.014360791, 0.0005611871, 0.011953329, 0.0102527095, 0.008020208, -0.01848987, -0.010581636, 0.022926878, -0.022213036, 0.00205929, -0.012653173, -0.03236077, -0.013178055, -0.012093298, 0.02385067, 0.0048814095, -0.008552089, -0.024228586, 0.008356133, -0.023122834, 0.035664033, 0.016978206, 0.009650843, -0.0033085106, 0.014003871, -0.022702927, -0.017076185, 0.02331879, 0.014444772, -0.020701375, 0.017132172, -0.0046119695, -0.021597175, -0.01007075, 0.0029463416, -0.01808396, -0.024858445, -0.029645376, -0.09142757, 0.015830463, 0.014472766, -0.0017233649, -0.0108895665, -0.0068374723, 0.025908211, 0.00043390304, -0.023682708, -0.021961093, -0.014374788, 0.020547409, -0.011890343, -0.03236077, -0.013255038, -0.008475106, 0.017174162, -0.012898118, -0.0034694748, 0.012954106, 0.015354569, 0.00993778, -0.0025544292, -0.019945543, 0.018111954, 0.0022325013, -0.01647432, 0.019665606, 0.00425155, 0.00608514, 0.017356122, -0.0006770987, -0.0048954063, -0.024732474, -0.0061971154, -0.0047099474, 0.02425658, 0.019763583, 0.007089416, -0.00041509475, -0.020883335, -0.03174491, 0.0077682645, 0.0029480914, -0.008713054, 0.021947097, -0.0028098722, 0.03280867, 0.0161104, -0.002533434, 0.015536529, 0.02089733, -0.01226126, -0.020435434, -0.0026209145, -0.008300145, -0.0032735185, -0.003852639, -0.0043880194, -0.0038386423, 0.00074358383, 0.009160953, 0.03963914, -0.015088629, -0.001432055, 0.029393433, -0.012443219, -0.011344465, 0.015634507, -0.02112128, -0.00017813208, 0.0026594058, 0.02089733, 0.025530295, -0.0063125896, 0.04918501, 0.00496889, -0.0035254622, -0.0308771, 0.018363897, -0.0069879387, -0.013569968, -0.022590952, -0.007523319, -0.00062592264, 0.02466249, -0.0246205, 0.021443209, -0.021415215, 0.018881781, -0.014458769, 0.011827357, -0.0121492855, -0.010581636, -0.012814137, 0.04901705, 0.0085380925, -0.013814913, 0.003397741, 0.006431563, 0.02081335, -0.0070859166, 0.0060431496, -0.038743343, -0.006431563, 0.00039388073, -0.03633588, -0.02179313, 0.012730156, -0.0027801287, 0.003303262, -0.007985216, 0.023640718, 0.017734038, -0.005315312, 0.009482881, 0.014654726, -0.014584742, -0.04103883, 0.012478212, 0.0048569147, -0.0118833445, 0.020281468, -0.0062950933, 0.032276787, -0.0174541, 0.0039996062, -0.018769806, 0.00035779504, -0.016306357, -0.01324804, 0.0060746428, -0.051956393, -0.021863114, 0.00034095507, 0.02810572, -0.016362345, 0.040870868, 0.0038631367, 0.0156625, 0.027825782, -0.016530307, 0.00062679744, 0.037175693, -0.0061201327, 0.0029970803, -0.021961093, -0.006025654, -0.0111625055, 0.0006543538, -0.029785344, 0.0098468, -0.024242584, -0.0064210654, -0.032248795, 0.002657656, 0.014822688, -0.00425155, 0.003964614, 0.036447857, 0.019567627, 0.026706032, 0.026034184, -0.018923772, -0.0043985173, -0.011540421, -0.008657066, 0.0036041946, -0.030261239, -0.0026489082, 0.0067639886, 0.01580247, -0.024368554, 0.018321905, -0.017524084, 0.003070564, 0.029617382, 0.034796227, 0.005826198, 0.0048849084, 0.025348336, -0.030513182, -0.03720369, 0.0143188005, -0.0092589315, -0.007446336, 0.00054281624, -0.032108825]}\n",
            "author: signorr\n",
            "board: HatePolitics-ptt\n",
            "chunk: 1\n",
            "content_type: comment\n",
            "media: ptt\n",
            "order: 24\n",
            "post_id: M.1617787676.A.06E\n",
            "rating: pos\n",
            "text: 休假 要給錢~\n",
            "title: [公告] wupaul 違反政黑板規2-16 前科*2 水桶14天\n",
            "total_chunks: 1\n",
            "year: 2021\n",
            "Vector length: 1536\n"
          ]
        }
      ],
      "source": [
        "attributes = [field.name for field in fields(ContentItem)]\n",
        "response = (\n",
        "    client.query.get(\"TestContentItem\", attributes)\n",
        "    .with_hybrid(\n",
        "        query=\"放假\"\n",
        "    )\n",
        "    .with_additional(\"vector\")\n",
        "    .with_limit(1)\n",
        "    .do()\n",
        ")\n",
        "response = response[\"data\"][\"Get\"][\"TestContentItem\"]\n",
        "for key, val in response[0].items():\n",
        "    print(f\"{key}: {val}\")\n",
        "print(f\"Vector length: {len(response[0]['_additional']['vector'])}\")"
      ],
      "id": "MZkM4JhTCsoC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3️⃣ Retrieving SoMe data from Weaviate**\n",
        "\n",
        "* <mark>Using **WeaviateHybridSearchRetriever** from LangChain</mark>\n",
        "* **Taiwan Social Media Corpus (SoMe)**: A large-scaled, diverse and linguistically-enriched social media corpus of Mandarin in Taiwan. For efficiency, the SoMe data has already been uploaded to Weaviate. Please check out [this notebook](https://colab.research.google.com/drive/16IqjfMMy2k1JpOlyr6KUIx6U0tP_d5lJ?usp=sharing) for more details."
      ],
      "metadata": {
        "id": "UAkpA-wZuPv1"
      },
      "id": "UAkpA-wZuPv1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_9w4xX8ouEH"
      },
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "from dataclasses import dataclass\n",
        "from pprint import pprint\n",
        "import os\n",
        "import weaviate\n",
        "from langchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ContentItem:\n",
        "    media: str          # media source of the PTT post/comment\n",
        "    content_type: str   # post/comment\n",
        "    author: str         # author of the post/comment\n",
        "    post_id: str        # id of the post\n",
        "    year: str           # year of the post\n",
        "    board: str          # board of the post\n",
        "    title: str          # title of the post\n",
        "    text: str           # content text of the post/comment\n",
        "    rating: str         # rating of the comment\n",
        "    order: int          # 0 for post, 1, 2, 3, ... for comments\n",
        "    chunk: int          # if text too long, split into chunks\n",
        "    total_chunks: int   # total number of chunks\n",
        "\n",
        "\n",
        "os.environ['WEAVIATE_ADMIN_PASS'] = \"weaviate-ultimate-forever-pass\""
      ],
      "id": "4_9w4xX8ouEH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TNv3ULgouEH"
      },
      "outputs": [],
      "source": [
        "client = weaviate.Client(\n",
        "    url=\"http://140.112.147.128:8000\",\n",
        "    auth_client_secret=weaviate.AuthApiKey(api_key=os.environ[\"WEAVIATE_ADMIN_PASS\"]),\n",
        "    # (connect timeout, read timeout) # type: ignore\n",
        "    timeout_config=(5, 30),\n",
        "    additional_headers={'X-OpenAI-Api-Key': openai_api_key}\n",
        ")\n",
        "\n",
        "attributes = [field.name for field in dataclasses.fields(ContentItem)]"
      ],
      "id": "-TNv3ULgouEH"
    },
    {
      "cell_type": "markdown",
      "source": [
        " <mark>WeaviateHybridSearchRetriever</mark> for searching keywords"
      ],
      "metadata": {
        "id": "TumEov4FDhc9"
      },
      "id": "TumEov4FDhc9"
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_docs(keyword, count=8):\n",
        "    retriever = WeaviateHybridSearchRetriever(\n",
        "        client=client,\n",
        "        index_name=\"ContentItem\",\n",
        "        text_key=\"text\",\n",
        "        alpha=0.5,              # The weight of the text key in the hybrid search.\n",
        "        attributes=attributes,  # The attributes to return in the results.\n",
        "        k=count,                # The attributes to return in the results.\n",
        "    )\n",
        "    r = retriever.get_relevant_documents(keyword)\n",
        "    return r"
      ],
      "metadata": {
        "id": "g9lMfdEvvtr6"
      },
      "id": "g9lMfdEvvtr6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retrieve_docs('筆電')\n",
        "pprint(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPjEyfQfQLAT",
        "outputId": "8ca51810-7307-4c60-e15f-d4932f81e177"
      },
      "id": "gPjEyfQfQLAT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='載下來了，沒想到多年後，手機、筆電、iPad換新後，', metadata={'author': 'maggiekiki', 'board': 'movie-ptt', 'chunk': 1, 'content_type': 'comment', 'media': 'ptt', 'order': 30, 'post_id': 'M.1641378653.A.A1F', 'rating': 'neu', 'title': 'Re: [討論] 目前的DVD與藍光是否漸漸走向淘汰了？', 'total_chunks': 1, 'year': '2022'}),\n",
            " Document(page_content=\"明天MBP 14'就到惹啦紀念一下最後一天用這台破爛筆電修他的錢早就超過當初買他的錢= =我這輩子再買雙A的產品我就是狗:)\", metadata={'author': 'aa871220 (NTU網美所阿肥)', 'board': 'NTU-ptt', 'chunk': 1, 'content_type': 'post', 'media': 'ptt', 'order': 0, 'post_id': 'M.1641531094.A.BD2', 'rating': '', 'title': '[廢文] acer筆電', 'total_chunks': 1, 'year': '2022'}),\n",
            " Document(page_content='每個人收藏實體的原因都不同像是畫質音效，喜歡實體感覺，方便轉賣或借人等等都非常有道理推文有人提到串流會下架，這也沒錯不過既然是收藏，也可以購買數位收藏像我自己是用iTunes收藏電影，自己喜歡的應該也買了一百多部比較新的電影，或是修復版，也都有4K畫質好處是隨點隨看，不限平台，想用電視，平板, 筆電,手機都可以蘋果也夠大，不太會倒，當然當年也沒有人認為諾基亞會倒真的擔心的話，購買完也是可以下載下來的我自己是數位派，實體這塊市場應該還會繼續萎縮', metadata={'author': 'A1bertPujols (The Machine)', 'board': 'movie-ptt', 'chunk': 1, 'content_type': 'post', 'media': 'ptt', 'order': 0, 'post_id': 'M.1609098699.A.DE7', 'rating': '', 'title': 'Re: [討論] 現在還有人會收藏實體光碟嗎？', 'total_chunks': 1, 'year': '2020'}),\n",
            " Document(page_content='https://ann.cc.ntu.edu.tw', metadata={'author': 'AAAB', 'board': 'NTU-ptt', 'chunk': 1, 'content_type': 'comment', 'media': 'ptt', 'order': 2, 'post_id': 'M.1668880269.A.426', 'rating': 'neu', 'title': '[失物] HP筆電', 'total_chunks': 1, 'year': '2022'}),\n",
            " Document(page_content='欸欸小弟阿肥啦剛剛熬夜寫作業，好不容易寫完準備要去睡了沒想到ceiba毛一堆，作業一直上傳不上去弄了十幾分鐘，試過電腦、筆電、手機、平板，都一直顯示連線錯誤好不容易壓線前一分鐘傳上去了，結果下載下來傳上去的資料夾卻是空的幹作業根本白寫了然後助教又很固執，不收遲交作業就算了之前有一次也是ceiba有問題傳不上去，deadline前email給助教他也不收跟助教吵他也不會鳥我，畢竟權力太不對等了疫情前作業交紙本的根本不會有這個問題啊這次作業拿0分不知道前面大半個學期的實驗課會不會白做了ceiba能不能強點= =哈哈 好笑的是我上次寄他不收 結果這次作業可能很多人都交不了吧 他又發了一個email說開放有寄email夾檔的同學到ceiba上補交其他的不收 乾他上次那樣跟我說，我想說不要再被洗臉一次，這次就沒在deadline前寄檔案給他了QQ「助教自己知道ceiba有問題為什麼不用Ntu cool」「deadline前上傳不了再來怪學生為什麼改寄email交」', metadata={'author': 'Kao0502 (學店仔)', 'board': 'NTU-ptt', 'chunk': 1, 'content_type': 'post', 'media': 'ptt', 'order': 0, 'post_id': 'M.1623306462.A.3D4', 'rating': '', 'title': '[問題] ceiba問題484很多啊', 'total_chunks': 1, 'year': '2021'}),\n",
            " Document(page_content='acer 跟asus', metadata={'author': 'aa871220', 'board': 'NTU-ptt', 'chunk': 1, 'content_type': 'comment', 'media': 'ptt', 'order': 7, 'post_id': 'M.1641531094.A.BD2', 'rating': 'neu', 'title': '[廢文] acer筆電', 'total_chunks': 1, 'year': '2022'}),\n",
            " Document(page_content='支持', metadata={'author': 'cuteSquirrel', 'board': 'NTU-ptt', 'chunk': 1, 'content_type': 'comment', 'media': 'ptt', 'order': 1, 'post_id': 'M.1641531094.A.BD2', 'rating': 'pos', 'title': '[廢文] acer筆電', 'total_chunks': 1, 'year': '2022'}),\n",
            " Document(page_content='雷文防雷資訊頁~~~~~~~~~~~~~~~~~~~ 雷文 主文分隔線 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~我是偶然看到Youtube的預告才想要看這部片的，爬了本板以後發現有很多致敬(?)各大遊戲的海報，更讓我想看。首先，我很喜歡脫稿玩家的原文名稱「Free Guy」的雙關。Free一詞有形容詞跟動詞的解釋方法，形容詞有自由的、無拘束的；動詞則有解放的意思整部電影劇情就是讓「Guy(台譯：蓋依)」這個人能夠自由地成為一個人工智慧在虛擬世界生活。這部電影不需要很多遊戲的理解，但如果對於遊戲的認識夠多，裡面長的像GTA的自由世界架構，像是當初GTAVC(俠盜列車手：罪惡都市)或早期遊戲這樣的補血機制。GTAV出現的搶劫任務，一般RPG常出現無聊的找東西任務等等都會使人感到驚喜。還有對戰時可以瞬間拿出的武器，長的像GTAV的車庫，傳送門2的Portal Gun(傳送槍)、G mod跟Half Life系列的重力槍、星際大戰的Light Saber(光劍)，無一不引起對於遊戲玩家的懷念，並想起甚麼時候可以數到3。其中也請到包含jacksepticeye等知名Youtuber，讓我突然覺得很親近，還搞出跟YT直播一樣的畫面，時不時露出的各家電競廠商的產品(我看到的包括Razer的耳機兩種、筆電；HyperX的耳機；DXRacer電競椅；各種七彩霓虹燈的自組電腦)甚至連Gawr Gura講的「Apex Predator」都拿來當梗(但我真的不確定是不是Gura先講的)，也直言不諱的講到Twitch跟Youtube，但可惜台灣翻譯沒有直接寫出這兩個直播平台的名字。真的是讓一個很愛玩遊戲、愛看人家玩遊戲的我感到親近的電影。但是對於沒有上述的插入內容，或許在一般人眼中只是一部CG效果不錯的影片。這跟我前幾年在威秀看4DX3D的Ready Player One有一樣的親近感，但聽說當時該片對於原著改編很大。非常推薦給有玩遊戲，尤其是可以自由殺人(?)的開放式砂盒遊戲的人去看這部影片。而這次在大直美麗華IMAX看，真的觀影體驗很好，要來研究國外有沒有原生IMAX電影院了Swat 筆電參號機(Swat-NB003)→https://i.imgur.com/qsPVDul.png品名 ASUS ROG Strix G713QM LCD: 17.3\" 2560*1440 165Hz 3ms LCDCPU: AMD R9-5900HX         RAM: DDR4-3200 16GB*2SSD: Hynix 1TB NVMe + WD SN550 1TB NVMeGPU: AMD Radeon            GPU: NVIDIA RTX3060 6GD6 115W※ swattw:轉錄至看板 C_Chat                                        08/15 21:14', metadata={'author': 'swattw (Swat-大師模式)', 'board': 'movie-ptt', 'chunk': 1, 'content_type': 'post', 'media': 'ptt', 'order': 0, 'post_id': 'M.1629032966.A.19D', 'rating': '', 'title': '[好雷] 脫稿玩家', 'total_chunks': 1, 'year': '2021'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2d664fc"
      },
      "source": [
        "## **4️⃣ Q&A over specific context**"
      ],
      "id": "a2d664fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad87c72b"
      },
      "source": [
        "\n",
        "- To employ a LLM for Q&A, we need to pass the relevant context that the LLM needs and the question that we want the LLM to answer\n",
        "\n",
        "- The process is like: `llm(context + question) ==> answer`"
      ],
      "id": "ad87c72b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: short text**"
      ],
      "metadata": {
        "id": "k54flk-sZsJW"
      },
      "id": "k54flk-sZsJW"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
        "\n",
        "context = \"\"\"\n",
        "Rachel 是 33歲\n",
        "Bob 是 55歲\n",
        "Kevin 是 66歲\n",
        "\"\"\"\n",
        "\n",
        "question = \"誰的年齡小於40歲?\""
      ],
      "metadata": {
        "id": "WbiaWcWENVRL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "WbiaWcWENVRL"
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm(context + question)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggPqnFUrNnfW",
        "outputId": "dcf0018e-fa8a-4ed1-ba38-48eb9ee90412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rachel 33歲\n"
          ]
        }
      ],
      "id": "ggPqnFUrNnfW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "385180ca"
      },
      "source": [
        "**Example: longer text**"
      ],
      "id": "385180ca"
    },
    {
      "cell_type": "code",
      "source": [
        "# select a longer text from our SoMe data on Weaviate\n",
        "docs = retrieve_docs('筆電')\n",
        "text = docs[2].page_content\n",
        "\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "bfa13204-4664-4ec8-8300-f3003c06f6ed",
        "id": "tREcS35U8ycu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'每個人收藏實體的原因都不同像是畫質音效，喜歡實體感覺，方便轉賣或借人等等都非常有道理推文有人提到串流會下架，這也沒錯不過既然是收藏，也可以購買數位收藏像我自己是用iTunes收藏電影，自己喜歡的應該也買了一百多部比較新的電影，或是修復版，也都有4K畫質好處是隨點隨看，不限平台，想用電視，平板, 筆電,手機都可以蘋果也夠大，不太會倒，當然當年也沒有人認為諾基亞會倒真的擔心的話，購買完也是可以下載下來的我自己是數位派，實體這塊市場應該還會繼續萎縮'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "id": "tREcS35U8ycu"
    },
    {
      "cell_type": "code",
      "source": [
        "# define the context & question\n",
        "context = text\n",
        "question = \"數位收藏的優點是什麼?\"\n",
        "\n",
        "# employ the LLM for QA\n",
        "output = llm(context + question)\n",
        "print(output.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW1IDQ6HZDdy",
        "outputId": "38855f28-a296-4ebe-f0f7-1c1d457a01e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "數位收藏的優點是可以隨時隨地觀看，不限平台，可以在電視、平板、筆電、手機等設備上觀看，而且可以下載下來，可以收藏更多的影片，而且不用擔心影片會下架，另外也可以購買4K畫質的影片，讓觀看體驗更加棒。\n"
          ]
        }
      ],
      "id": "yW1IDQ6HZDdy"
    },
    {
      "cell_type": "markdown",
      "id": "1bbdb1dc",
      "metadata": {
        "id": "1bbdb1dc"
      },
      "source": [
        "## **5️⃣ Summarization**\n",
        "\n",
        "For articles, transcripts, chat history, Slack/Discord, customer interactions, legal documents, podcasts, Tweets, code bases, movie reviews, etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = weaviate.Client(\n",
        "    url=\"http://140.112.147.128:8000\",\n",
        "    auth_client_secret=weaviate.AuthApiKey(api_key=os.environ[\"WEAVIATE_ADMIN_PASS\"]),\n",
        "    # (connect timeout, read timeout) # type: ignore\n",
        "    timeout_config=(5, 30),\n",
        "    additional_headers={'X-OpenAI-Api-Key': openai_api_key}\n",
        ")"
      ],
      "metadata": {
        "id": "ZuiEZ3sGR0Fg"
      },
      "id": "ZuiEZ3sGR0Fg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Initialize a WeaviateHybridSearchRetriever for searching keywords'''\n",
        "def retrieve_docs(keyword, count=8):\n",
        "    retriever = WeaviateHybridSearchRetriever(\n",
        "        client=client,\n",
        "        k=count,\n",
        "        # weighting for each search algorithm (alpha = 0 (sparse, BM25), alpha = 1 (dense), alpha = 0.5 (equal weight for sparse and dense))\n",
        "        alpha=0.5,\n",
        "        index_name=\"ContentItem\",\n",
        "        text_key=\"text\",\n",
        "        attributes=attributes,\n",
        "    )\n",
        "    r = retriever.get_relevant_documents(keyword)\n",
        "    return r"
      ],
      "metadata": {
        "id": "NclsZpZdYxu4"
      },
      "id": "NclsZpZdYxu4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "您是生成文字摘要的助手\n",
        "使用者將傳入一段文本，請您產生此文本的摘要\n",
        "摘要的token數量必須少於100\n",
        "只輸出摘要\n",
        "\"\"\"\n",
        "# define the ChatPrompt\n",
        "human_template = \"{text}\"\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", template),\n",
        "    (\"human\", human_template),\n",
        "])\n",
        "\n",
        "# define the LLM\n",
        "llm = ChatOpenAI(openai_api_key=openai_api_key, verbose=True,)\n",
        "\n",
        "# define the chain\n",
        "chain = chat_prompt | llm"
      ],
      "metadata": {
        "id": "04f1TW4vN19F"
      },
      "id": "04f1TW4vN19F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select a text from our SoMe data on Weaviate\n",
        "docs = retrieve_docs('筆電')\n",
        "text = docs[2].page_content\n",
        "\n",
        "# the original text\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "kkJcoALG3NoC",
        "outputId": "bfa13204-4664-4ec8-8300-f3003c06f6ed"
      },
      "id": "kkJcoALG3NoC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'每個人收藏實體的原因都不同像是畫質音效，喜歡實體感覺，方便轉賣或借人等等都非常有道理推文有人提到串流會下架，這也沒錯不過既然是收藏，也可以購買數位收藏像我自己是用iTunes收藏電影，自己喜歡的應該也買了一百多部比較新的電影，或是修復版，也都有4K畫質好處是隨點隨看，不限平台，想用電視，平板, 筆電,手機都可以蘋果也夠大，不太會倒，當然當年也沒有人認為諾基亞會倒真的擔心的話，購買完也是可以下載下來的我自己是數位派，實體這塊市場應該還會繼續萎縮'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run the chain for summary\n",
        "output = chain.invoke( {\"text\": text} )\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5_pYg53P4Pc",
        "outputId": "46df932d-10c3-4afb-9308-31d9cbfb39a3"
      },
      "id": "_5_pYg53P4Pc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='實體收藏的原因各有不同，如畫質音效、喜歡實體感覺、方便轉賣或借人等。但數位收藏也有其優勢，例如隨點隨看、不限平台、可下載等。市場上實體收藏可能會繼續萎縮。')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "VpJhhnS-cIt5"
      },
      "id": "VpJhhnS-cIt5"
    },
    {
      "cell_type": "markdown",
      "id": "751c6359",
      "metadata": {
        "id": "751c6359"
      },
      "source": [
        "**For a much longer text...**\n",
        "\n",
        "It may become a pain to manage and exceed token limits. 🥲🥲\n",
        "\n",
        "LangChain has out of the box support for different methods to summarize via their [load_summarize_chain](https://python.langchain.com/en/latest/use_cases/summarization.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf8eda6",
      "metadata": {
        "id": "5bf8eda6"
      },
      "source": [
        "\n",
        "### step.1\n",
        "<mark> we need to chunk the text into smaller pieces. </mark>\n",
        "\n",
        "  - [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html) is easy to control; you can also check out [other available splitters](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html).\n",
        "\n",
        "```\n",
        "    length_function: how the length of chunks is calculated. Defaults to just counting number of characters, but it's pretty common to pass a token counter here.\n",
        "    chunk_size: the maximum size of your chunks (as measured by the length function).\n",
        "    chunk_overlap: the maximum overlap between chunks. It can be nice to have some overlap to maintain some continuity between chunks (e.g. do a sliding window).\n",
        "    add_start_index: whether to include the starting position of each chunk within the original document in the metadata.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3441484b",
      "metadata": {
        "id": "3441484b"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a long TEXT\n",
        "texts = retrieve_docs('學校',150)\n",
        "text = texts[147].page_content\n",
        "\n",
        "num_tokens = llm.get_num_tokens(text)\n",
        "print (f\"There are {num_tokens} tokens in the text\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q7NGXXQAE_T",
        "outputId": "893060e9-529a-441c-d07f-e92c9c465263"
      },
      "id": "8q7NGXXQAE_T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 7995 tokens in the text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the TEXT into small docs\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 700,   # we set a small chunk size, just to show.\n",
        "    chunk_overlap  = 50,\n",
        "    length_function = len,\n",
        "    add_start_index = True,\n",
        ")\n",
        "\n",
        "# Inspect some small docs\n",
        "docs = text_splitter.create_documents([text])\n",
        "print(docs[0])\n",
        "print(docs[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTySo4Z4AOcf",
        "outputId": "794074f4-2266-47f6-b9e5-b67bcb48859c"
      },
      "id": "tTySo4Z4AOcf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='繼上次Part1   https://moptt.tw/p/movie.M.1643728037.A.FF5介紹了幾部比較有名的歐洲片之後 Part2要來介紹一些在台灣較冷門的電影 大部分在台灣沒有上映 不過在各大影音網站還是找得到 還是要強調所有推薦的電影都是憑我個人喜好 所以如果覺得不好看不要罵我XDDD一樣會有我認為的闔家觀賞程度(一到五顆星) 方便想找片跟小朋友一起看的人 這邊不是以戲院的電影分級 普遍級不一定是五顆星 而是我覺得小孩看不看得懂或有沒有興趣另外有些語言的字母會有上下標PTT無法顯示 所以我會用最接近的英文字母代替(去掉上下標）德語片part2：（因為德語片還頗多 所以分兩次介紹）1.《Ein Sommer in Kroatien克羅埃西亞的夏日時光》這部我之前有打過一篇好雷文 https://moptt.tw/p/movie.M.1631623081.A.E67所以就不再多打劇情簡介了 不想被爆雷記得注意防雷頁喔XD闔家觀賞程度：四顆星畢竟是成年人的愛情電影 給小學中年級以下的孩子看他們可能會覺得無聊興趣缺缺XD 所以只給四顆星2.《Nachbarn suss-sauer王家不是你家》劇情簡介：一個德國家庭發現新搬來的中國鄰居一家人在各方面都比他們強，學校、職場、運動無一不是，德國家庭的嫉妒引發競爭，接著是天翻地覆的對戰，也有一連串的爆笑事件發生。這部是以幽默詼諧的方式講族群差異 衝突及融合 德國蠻多這類的片 如果放假想要跟家人(尤其老人家)一起看電影放鬆一起笑 這部非常推闔家觀賞程度：四顆星會給四顆星主要也是因為這畢竟是給大人看的電影' metadata={'start_index': 0}\n",
            "page_content='這部非常推闔家觀賞程度：四顆星會給四顆星主要也是因為這畢竟是給大人看的電影 國小低年級以下的小朋友可能會看不懂 所以沒給到五顆3.《Dreiviertelmond四分之三的月亮》劇情簡介：哈特穆特(Hartmut)是一名計程車司機。他的妻子忽然求去，從此哈特穆特之後陷入人生低潮。某天，六歲女孩海雅特(Hayat)和母親搭上他的計程車，發生了一連串意外事件，他必須照顧海雅特，也因此再次感受到人生的喜悅。非常溫馨感人的一部片 跟《Nachbarn suss-sauer》一樣是講述不同族群間的互動關係 Hartmut跟Hayat兩個其實語言不太通的老人及小孩 在劇中情同祖孫的互動非常感人且讓人回味 喜歡親情類的人絕對會喜歡這部另外雖然放在德語片 但這部也有部分是土耳其語 因為Hayat的母親是土耳其人闔家觀賞程度：4.5顆星這部我覺得如果給幼稚園小孩看應該是沒問題 但我家畢竟沒有這麼小的小孩 沒有真的「市場調查」過XD 怕對小小孩來說還是偏無聊 加上因為不是中文電影 怕小孩子可能看不懂字幕又聽不懂就覺得無聊 所以給4.5哈哈俄語片：1.《Сестрeнка親愛的妹妹》(英文片名:My little sister)劇情簡介：正值二戰的蘇聯，小小年紀的Yamil殷殷期盼能見到未曾謀面的父親從戰後歸來。有一天，母親帶回一位精神受創的孤兒Oksana，Yamil決定用滿懷關愛與希望之情，視她如自己的親妹妹。俄文片名的意思是Sister 對於這部我有點難想出什麼心得 因為劇情簡介就差不多說完了很平舖直敘的一部片 但又非常感人 不會覺得無聊 總之很好看' metadata={'start_index': 654}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7547a3",
      "metadata": {
        "id": "3e7547a3"
      },
      "source": [
        "### step.2\n",
        "<mark>we need to load up a summarize chain that uses the method \"map-reduce.\"</mark>\n",
        "- <img src=\"https://drive.google.com/uc?id=1ifElnWJ9xrKWpB95YLQR_mpjImhQwB5x\" width=\"450\"/>\n",
        "\n",
        "- The chain will make successive calls (for summarization) to the LLM for us.\n",
        "\n",
        "- Check out [this YT video](https://www.youtube.com/watch?v=f9_BWhCI4Zo) for other chain types besides `map-reduce`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the summary chain (type=\"map_reduce\")\n",
        "chain = load_summarize_chain(llm,\n",
        "                             chain_type=\"map_reduce\",\n",
        "                             verbose=True)\n",
        "                            # verbose: to see the process of the chain"
      ],
      "metadata": {
        "id": "UjRu-A9nTCr_"
      },
      "id": "UjRu-A9nTCr_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step.3\n",
        "<mark>Finally, we can run the chain using the small docs.</mark>"
      ],
      "metadata": {
        "id": "p5ZrNVUdWdha"
      },
      "id": "p5ZrNVUdWdha"
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain\n",
        "## The chain will run through the split documents,\n",
        "## summarize each chunk,\n",
        "## and get a summary of the summary.\n",
        "\n",
        "output = chain.run(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MDO4jtoA_1c",
        "outputId": "70aaa905-01fc-4994-f02f-e1f745866aed"
      },
      "id": "9MDO4jtoA_1c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"繼上次Part1   https://moptt.tw/p/movie.M.1643728037.A.FF5介紹了幾部比較有名的歐洲片之後 Part2要來介紹一些在台灣較冷門的電影 大部分在台灣沒有上映 不過在各大影音網站還是找得到 還是要強調所有推薦的電影都是憑我個人喜好 所以如果覺得不好看不要罵我XDDD一樣會有我認為的闔家觀賞程度(一到五顆星) 方便想找片跟小朋友一起看的人 這邊不是以戲院的電影分級 普遍級不一定是五顆星 而是我覺得小孩看不看得懂或有沒有興趣另外有些語言的字母會有上下標PTT無法顯示 所以我會用最接近的英文字母代替(去掉上下標）德語片part2：（因為德語片還頗多 所以分兩次介紹）1.《Ein Sommer in Kroatien克羅埃西亞的夏日時光》這部我之前有打過一篇好雷文 https://moptt.tw/p/movie.M.1631623081.A.E67所以就不再多打劇情簡介了 不想被爆雷記得注意防雷頁喔XD闔家觀賞程度：四顆星畢竟是成年人的愛情電影 給小學中年級以下的孩子看他們可能會覺得無聊興趣缺缺XD 所以只給四顆星2.《Nachbarn suss-sauer王家不是你家》劇情簡介：一個德國家庭發現新搬來的中國鄰居一家人在各方面都比他們強，學校、職場、運動無一不是，德國家庭的嫉妒引發競爭，接著是天翻地覆的對戰，也有一連串的爆笑事件發生。這部是以幽默詼諧的方式講族群差異 衝突及融合 德國蠻多這類的片 如果放假想要跟家人(尤其老人家)一起看電影放鬆一起笑 這部非常推闔家觀賞程度：四顆星會給四顆星主要也是因為這畢竟是給大人看的電影\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"這部非常推闔家觀賞程度：四顆星會給四顆星主要也是因為這畢竟是給大人看的電影 國小低年級以下的小朋友可能會看不懂 所以沒給到五顆3.《Dreiviertelmond四分之三的月亮》劇情簡介：哈特穆特(Hartmut)是一名計程車司機。他的妻子忽然求去，從此哈特穆特之後陷入人生低潮。某天，六歲女孩海雅特(Hayat)和母親搭上他的計程車，發生了一連串意外事件，他必須照顧海雅特，也因此再次感受到人生的喜悅。非常溫馨感人的一部片 跟《Nachbarn suss-sauer》一樣是講述不同族群間的互動關係 Hartmut跟Hayat兩個其實語言不太通的老人及小孩 在劇中情同祖孫的互動非常感人且讓人回味 喜歡親情類的人絕對會喜歡這部另外雖然放在德語片 但這部也有部分是土耳其語 因為Hayat的母親是土耳其人闔家觀賞程度：4.5顆星這部我覺得如果給幼稚園小孩看應該是沒問題 但我家畢竟沒有這麼小的小孩 沒有真的「市場調查」過XD 怕對小小孩來說還是偏無聊 加上因為不是中文電影 怕小孩子可能看不懂字幕又聽不懂就覺得無聊 所以給4.5哈哈俄語片：1.《Сестрeнка親愛的妹妹》(英文片名:My little sister)劇情簡介：正值二戰的蘇聯，小小年紀的Yamil殷殷期盼能見到未曾謀面的父親從戰後歸來。有一天，母親帶回一位精神受創的孤兒Oksana，Yamil決定用滿懷關愛與希望之情，視她如自己的親妹妹。俄文片名的意思是Sister 對於這部我有點難想出什麼心得 因為劇情簡介就差不多說完了很平舖直敘的一部片 但又非常感人 不會覺得無聊 總之很好看\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"因為劇情簡介就差不多說完了很平舖直敘的一部片 但又非常感人 不會覺得無聊 總之很好看 很感人就是對於這部電影我唯二想得到的形容XD 而且是會讓我想再看第二次的片(會讓我想再二刷的片真的不多很多片即便覺得好看也會覺得看一次就夠了) 看了保證不會後悔(我覺得啦lol) 另外雖然我放在俄語片 但由於這部片是改編自巴什科爾托斯坦民族詩人穆斯泰極d里姆(MustaiKarim)的故事《我們家的喜悅》(Радость нашего дома）片中男主角Yamil其實是俄羅斯中部的巴什基爾人 所以片中有超過八成的劇情都是說巴什基爾語(是說這本書似乎有點冷門 維基上連俄文條目都沒有 google也沒有人在賣英文版的 但用俄文搜竟然有免費的電子書 所以如果有興趣可以用網頁翻譯的功能看XD)闔家觀賞程度：四顆星其實我個人覺得可以給到五顆 可能是因為片中雖然沒有戰爭場面但還是有德軍「拿槍」(沒有開槍殺人)的畫面 以及男主角被村子其他小孩欺負的橋段 所以被國外歸在6+的電影(但台灣的影音平台是歸在普遍級 這部分就看大家要相信誰XD) 所以我就還是以最保守的歸類給四顆2.《Марафон желании(俄文拉丁化為Marafon zhelaniy)七個願望》（英文片名：The marathon of desires)劇情簡介：夢幻婚禮是每個女孩的夢想，美甲師Marina終於盼到了這一天，卻在婚禮前夕弄丟了護照。遍尋不至之下，她報名參加心靈導師推薦的祈願馬拉松，她向宇宙許下七個願望，然而宇宙似乎沒有聽清楚。這部其實就是愛情喜劇片 主要是在講我們經常覺得自己失去了什麼 想去追回\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"主要是在講我們經常覺得自己失去了什麼 想去追回 但其實有時候失去了一樣反而會得到另一樣 你認為的運氣或巧合 也許正是因為你自己去追求所以才發生的 我個人很喜歡電影最後的獨白 但以防爆雷有興趣就大家自己去看囉XD 另外這部是2020年俄國賣座片亞軍 如果想知道俄國人都喜歡什麼片的話可以看看 我覺得其實跟台灣差不多啦 每年賣座的國片也幾乎都是愛情喜劇XD闔家觀賞程度：四顆星因為是成年人的愛情電影 小小孩可能會沒什麼興趣 所以給四顆3.《Clay Pit家就是個坑》劇情簡介：故事背景是90年代的偏遠俄國小鎮上。在這裡可以忘卻大城市的煩憂，癒療心靈的傷口。因此Mila在莫斯科打拼失利之後，決定搬回老家和媽媽住。她的姐姐Galya即將嫁給來自中亞的迷人男子Rustam，卻不知情感風暴即將來襲，一家人即將面對悲慘的困境。這部是改編自Olga Pogodina-Kuzmina的劇本《Clay Pit》不過先小小爆雷 就是由於原本的劇本是個超級黑暗的大悲劇 這部電影把他改成Happy ending劇中每個人都是悲劇角色 這整部片其實蠻黑暗的 但劇情又挺吸引人會讓人想一直看下去主要是在講當每個人都自私的追求自己想要的東西時 是否其實是建立在別人的痛苦之上呢 非常引人省思的一部片闔家觀賞程度：兩顆星雖然已經改成Happy ending了 但劇情我認為還是蠻黑暗的 真的不太適合國小以下小孩看甚至國中生都要斟酌(要看你覺得你家小孩心智年齡如何 然後國一跟國三也差很多)  還有雖然我真的覺得這部很好看但如果是要跟老人家一起看(尤其是過年這種很歡樂的氣氛)千萬不要選這部 所以只給了兩顆\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"所以只給了兩顆 不過我很推薦給再婚或想尋找第二春的單親爸媽 就不先爆雷說為什麼 有興趣自己去看囉XDDD法語片：（上次漏了一部）《Coup de Foudre a Saint-Petersbourg愛在聖彼得堡》劇情簡介：個性活潑的單親媽Marie 收到意外的聖誕禮物。出身古老白俄羅斯家族的她，繼承了一座位在聖彼得堡近郊的遊樂園！她盡己所能讓冷清的生意好轉，但經理Vania 擔心她會越弄越糟。為了挽救遊樂園，意見不合的兩人不得不攜手合作，當他們的關係拉近之後，愛苗也悄悄滋長。這部的調性跟類型跟《克羅埃西亞的夏日時光》很類似 就是一部愛情喜劇 非常適合想放鬆的時候看 因為劇情蠻好懂的 所以就不贅述闔家觀賞程度：四顆星凡是大人的愛情電影我都一律給四顆 因為我想小小孩大概會覺得無聊興趣缺缺XD愛沙尼亞語片：《Eia joulud Tondikakul貓頭鷹之森(貓頭鷹森林)》（英文片名：Phantom Owl Forest劇情簡介：愛沙尼亞片名意思是Eia's Christmas at Phantom Owl Farm。愛亞的父母將她送到郊外的牧場，她在那裡度過了一個難忘的聖誕節。她發現大自然的美，也認識了不少野生動物。令她意想不到的是，她成功解救一座住著幽靈貓頭鷹的森林，撮合一對戀人，更發現了自己家中的秘密。這部之前有板友打過好雷文  https://moptt.tw/p/movie.M.1602749886.A.A79有興趣可以去看(不想被爆雷記得注意防雷頁) 所以我就不多講  我也是超推這部 喜歡親情類的大自然的都一定會愛這部闔家觀賞程度：五顆星這部本來就是給小朋友看的\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"我也是超推這部 喜歡親情類的大自然的都一定會愛這部闔家觀賞程度：五顆星這部本來就是給小朋友看的 所以當然是五顆星芬蘭語片：《Mielensapahoittaja我家來個怪老爹》(英文片名：The Grump）劇情簡介：他會毀了你的一天！脾氣暴躁的怪老爹跌了一跤，不得不搬到城裡借住兒子媳婦家。面對具有商業頭腦的精明媳婦，老派頑固的他受到了考驗。兩個人立刻起衝突，還引發爆笑後果，忍無可忍的媳婦希望他快點離開。但她即將發現老頑固的另外一面，怪老爹也必須向這位現代女性學習學習。悲喜劇的故事逐漸演變成一部關於新發現、寬容和縮小世代鴻溝的動人故事。這部是改編自芬蘭作家Tuomas Kyro 同名暢銷小說 是2014年芬蘭票房冠軍怪老爹是個活在過去 不相信現代科技的頑固老頭 這部主要在講述傳統農村與現代化都市的人如何在價值觀衝突中磨合 同時也在反諷現代社會 非常幽默又有深度的一部片闔家觀賞程度：4.5顆星雖然是大人的電影 但我覺得這部蠻淺顯易懂的 加上有蠻多很幽默好笑的橋段 小孩子看應該不會覺得無聊 不過畢竟我還是沒有實際「市場調查」過\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"加上有蠻多很幽默好笑的橋段 小孩子看應該不會覺得無聊 不過畢竟我還是沒有實際「市場調查」過 所以給4.5顆XDDD保加利亞語片：《жажда極度乾燥》（英文片名：Thirst)劇情簡介：新銳導演賽德羅絲特索爾卡瓦爾執導。導演的首部作品，表面平和，精準使用水與欲望的意向，用五個無名角色鋪陳出人類生存的原始法則。在水源貧濟的偏遠山丘，一家三口靠著媽媽的洗衣店維生。前來鑽井的父女鑿不出水，卻掘出這家人原本已乾涸的欲望。天真的青春期男孩被蠻橫難馴又充滿魅力的女孩所吸引，母親與鑽井男人在一排排晾著的床單後隱藏被滋潤的情事……乾燥之地小心火苗，烈焰燃起再難撲滅。以保加利亞貧困地區為背景，描述夏季乾旱時的故事。原始片名中的「thirst」（渴，保加利亞文跟英文片名意思一樣）是指對水的嚮往，但也包含其他意義：對愛的渴求。本片講述一個住在山頂上的家庭，家中的母親在幾家旅館洗衣服為生，因此需要水，但是配給的水量不夠使用，因此她找了一名男子幫忙，這名男子和他的小女兒一起在山上鑽探水源這部片中所有的角色都沒有名字 並且導演在很多情節都是用暗示的手法 整部片到結尾之前其實都沒什麼起伏 不過結局真的讓我非常非常震撼 很耐人尋味的一部片 每個角色都在追求自己渴望的東西 但最後每個人的渴望加在一起卻似乎一發不可收拾另外這裡我必須要先小小爆雷一下 這是一部悲劇 所以不喜歡悲劇結尾的人就自己斟酌然後如果要挑片跟長輩一起看這部也不推闔家觀賞程度：三顆星雖然這部是悲劇 但劇情並沒有像《Clay Pit家就是個坑》那麼黑暗 不過由於劇中運用非常多暗喻手法 加上整部戲到結局前都蠻平淡的 我想國小以下的小朋友應該是看不懂\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"不過由於劇中運用非常多暗喻手法 加上整部戲到結局前都蠻平淡的 我想國小以下的小朋友應該是看不懂 也會覺得無聊 加上又是悲劇\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\" This article introduces two lesser-known European films that are not available in theaters in Taiwan, but can be found on streaming sites. The first is \"Ein Sommer in Kroatien\" and the second is \"Nachbarn suss-sauer\". Both films are recommended for adults, but may not be suitable for younger children. The first is a romantic drama and the second is a comedy about cultural differences.\n",
            "\n",
            " Dreiviertelmond四分之三的月亮 is a movie for adults that follows the story of Hartmut, a taxi driver whose wife suddenly leaves him, and Hayat, a six-year-old girl he meets while driving. The two form a bond despite their language barrier, and Hartmut is able to find joy in life again. My Little Sister is another Russian movie that follows the story of Yamil, a young boy who takes in an orphaned girl during World War II. Both movies are heartwarming and enjoyable to watch.\n",
            "\n",
            " \n",
            "Marina, a manicurist, loses her passport on the eve of her dream wedding. She signs up for a spiritual marathon to make seven wishes to the universe, but the universe doesn't seem to listen. This romantic comedy follows Marina's journey to get back what she has lost.\n",
            "\n",
            " This movie is set in a remote Russian town in the 90s and follows the story of Mila, who moves back home after failing in Moscow, and her sister Galya, who is about to marry a man from Central Asia. The movie is a dark comedy that follows the characters as they face a tragic situation and ultimately come to a happy ending. It is not suitable for children and is best enjoyed by adults.\n",
            "\n",
            " This article recommends two French and Estonian films for single parents looking for a second chance at love. The French film, \"Coup de Foudre a Saint-Petersbourg,\" follows a single mother who inherits a theme park near St. Petersburg and must work with the manager to save it. The Estonian film, \"Eia joulud Tondikakul,\" follows a young girl who spends an unforgettable Christmas at a farm and discovers the beauty of nature, a phantom owl forest, and a family secret. Both films are recommended for all ages.\n",
            "\n",
            "\n",
            "The Grump is a Finnish movie about a grumpy old man who moves in with his son and daughter-in-law and is tested by her modern ways. It is based on a bestselling novel by Tuomas Kyro and is a comedy-drama about new discoveries, tolerance, and bridging the generational gap. It is suitable for all ages, with humorous scenes and a light-hearted message about traditional rural life and modern city life.\n",
            "\n",
            " \n",
            "Thirst is a Bulgarian film directed by Svetoslav Ovcharov. It follows five unnamed characters as they navigate the primitive rules of survival in a remote mountain village with scarce water resources. The story follows a mother and her teenage son, as well as a father and daughter who come to drill for water, and the romantic entanglement that ensues. The film uses metaphors to explore the themes of water and desire, and ends with a tragic conclusion. It is not suitable for young children, but is an intriguing and thought-provoking film.\n",
            "\n",
            " This play uses a lot of metaphors and is quite slow-paced, so it may be too difficult for children under elementary school age to understand and may be boring for them. It is also a tragedy.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuckCTiWVGzL",
        "outputId": "e3292822-46c4-49d2-dbcd-24db9e41e589"
      },
      "id": "fuckCTiWVGzL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(' This article recommends two European films for adults, \"Ein Sommer in '\n",
            " 'Kroatien\" and \"Nachbarn suss-sauer,\" as well as two French and Estonian '\n",
            " 'films, \"Coup de Foudre a Saint-Petersbourg\" and \"Eia joulud Tondikakul,\" for '\n",
            " 'single parents looking for a second chance at love. It also recommends the '\n",
            " 'Finnish movie \"The Grump\" and the Bulgarian film \"Thirst\" for all ages. All '\n",
            " 'of these films are not suitable for young children and are best enjoyed by '\n",
            " 'adults.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "本文推薦兩部適合成人觀賞的歐洲電影，《克羅埃西亞的夏日》和《Nachbarn suss-sauer》，以及兩部法國和愛沙尼亞電影，《聖彼得堡的Coup de Foudre a Saint-Petersbourg》和《Eia joulud Tondikakul》 ，推薦給尋求第二次愛情機會的單親父母。它也向所有年齡層推薦芬蘭電影《脾氣暴躁》和保加利亞電影《口渴》。所有這些電影都不適合幼兒觀看，最適合成年人觀看。\n"
      ],
      "metadata": {
        "id": "Uuzn0ZTgdNhj"
      },
      "id": "Uuzn0ZTgdNhj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6️⃣ Agents**\n",
        "\n",
        "- The core idea: use an LLM to  **choose a sequence of actions** to take.\n",
        "  - In `Chains`, a sequence of actions is hardcoded in the codes.\n",
        "  - In `Agents`, a LM is used as a **reasoning engine** to determine which actions to take and in which order.\n",
        "- `Agent` is powered by a LM and a prompt; the inputs are:\n",
        "\n",
        "  - a list of available tools\n",
        "  - the user input\n",
        "  - any previously executed steps (intermediate_steps)\n",
        "\n",
        "- The `Agent` returns either the next action to take or the final response to send to the user (AgentAction or AgentFinish).\n",
        "\n",
        "- For a full list of agent types see [agent types](https://python.langchain.com/docs/modules/agents/agent_types/)"
      ],
      "metadata": {
        "id": "kXfs7y3rKxOW"
      },
      "id": "kXfs7y3rKxOW"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import tool\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.tools.render import format_tool_to_openai_function   # let the agent know what tools it can use\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions  # format intermediate steps to messages\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser   # convert the output message into an agent action/agent finish"
      ],
      "metadata": {
        "id": "QCSZu7FrKzHD"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QCSZu7FrKzHD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a LLM to control the agent\n",
        "llm = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "juc7Wh_VNHnt"
      },
      "execution_count": null,
      "outputs": [],
      "id": "juc7Wh_VNHnt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple tool\n",
        "@tool\n",
        "def get_word_length(word: str) -> int:\n",
        "    \"\"\"Returns the length of a word.\"\"\"\n",
        "    return len(word)\n",
        "\n",
        "tools = [get_word_length]"
      ],
      "metadata": {
        "id": "Zx-3CGUlMcft"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Zx-3CGUlMcft"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Because `OpenAI Function Calling` is finetuned for tool usage, we hardly need any instructions on how to reason, or how to output format.\n",
        "- We just have 2 input variables: `input` (for the user question) and `agent_scratchpad` (for any previous steps taken)"
      ],
      "metadata": {
        "id": "iD4_Xe17Ndwo"
      },
      "id": "iD4_Xe17Ndwo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prompt\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are very powerful assistant, but bad at calculating lengths of words.\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])"
      ],
      "metadata": {
        "id": "Lk5OTYqcNP7v"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Lk5OTYqcNP7v"
    },
    {
      "cell_type": "code",
      "source": [
        "# Bind the tools to the LLM\n",
        "llm_with_tools = llm.bind(\n",
        "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
        ")"
      ],
      "metadata": {
        "id": "VlOv_VGIN0DM"
      },
      "execution_count": null,
      "outputs": [],
      "id": "VlOv_VGIN0DM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agent\n",
        "agent = {\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps'])\n",
        "    } | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()"
      ],
      "metadata": {
        "id": "1Wl5ahl-ObRf"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1Wl5ahl-ObRf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask\n",
        "output = agent.invoke({\n",
        "    \"input\": \"how many letters in the word, language?\",\n",
        "    \"intermediate_steps\": []\n",
        "})\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cRAcJnQOSIM",
        "outputId": "00d9d4d7-e620-473b-a618-15ab5ab02d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentActionMessageLog(tool='get_word_length', tool_input={'word': 'language'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'language'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_word_length', 'arguments': '{\\n  \"word\": \"language\"\\n}'}})])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "id": "3cRAcJnQOSIM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ⬆️⬆️⬆️ It responds with an `AgentAction` to take (it's actually an `AgentActionMessageLog` - a subclass of `AgentAction` which also tracks the full message log). So this is just the first step - now we need to write a runtime for this. The simplest one is just one that continuously loops, calling the agent, then taking the action, and repeating until an `AgentFinish` is returned.\n",
        "\n",
        "> Yet, `AgentExecutor` bundles up all of the above and adds in error handling, early stopping, tracing, and other quality-of-life improvements that reduce safeguards we need to write ⬇️⬇️⬇️\n"
      ],
      "metadata": {
        "id": "E9N5OmFaPctm"
      },
      "id": "E9N5OmFaPctm"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "output = agent_executor.invoke({\"input\": \"how many letters in the word, language?\"})\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j133bEvPIY-",
        "outputId": "6fc2bd4d-3298-46df-8345-9275a1938de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThere are 5 letters in the word \"educa\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how many letters in the word educa?',\n",
              " 'output': 'There are 5 letters in the word \"educa\".'}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "id": "6j133bEvPIY-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*For defining advanced custom tools, please check out [LangChain Tools](https://python.langchain.com/docs/modules/agents/tools/custom_tools).*"
      ],
      "metadata": {
        "id": "3zAoce_eQaIa"
      },
      "id": "3zAoce_eQaIa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More\n",
        "\n",
        "Other use cases in LangChain (which will not be covered today)."
      ],
      "metadata": {
        "id": "prkNs0JIF9QM"
      },
      "id": "prkNs0JIF9QM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VectorStore"
      ],
      "metadata": {
        "id": "TXAn43qlS_c_"
      },
      "id": "TXAn43qlS_c_"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Load the document in the repo folder, split it into chunks, embed each chunk and load it into the vector store.\n",
        "raw_documents = TextLoader('./state_of_the_union.txt').load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "db = Chroma.from_documents(documents, OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "MJm5iqyATBiU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MJm5iqyATBiU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask a question\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "oIYbTOaBUyuC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "oIYbTOaBUyuC"
    },
    {
      "cell_type": "markdown",
      "id": "d3d04dc9",
      "metadata": {
        "id": "d3d04dc9"
      },
      "source": [
        "## Extraction\n",
        "\n",
        "Extraction is the process of parsing data from a piece of text. This is commonly used with output parsing in order to *structure* our data.\n",
        "\n",
        "* **Deep Dive** - [Use LLMs to Extract Data From Text (Expert Level Text Extraction](https://youtu.be/xZzvwR9jdPA), [Structured Output From OpenAI (Clean Dirty Data)](https://youtu.be/KwAXfey-xQk)\n",
        "* **Examples** - [OpeningAttributes](https://twitter.com/GregKamradt/status/1646500373837008897)\n",
        "* **Use Cases:** Extract a structured row from a sentence to insert into a database, extract multiple rows from a long document to insert into a database, extracting parameters from a user query to make an API call\n",
        "\n",
        "- A popular library for advanced extraction is [Kor](https://eyurtsev.github.io/kor/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904d43c0",
      "metadata": {
        "id": "904d43c0"
      },
      "outputs": [],
      "source": [
        "# To help construct our Chat Messages\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# We will be using a chat model, defaults to gpt-3.5-turbo\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# To parse outputs and get structured data back\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "\n",
        "chat_model = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo', openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6923ca8b",
      "metadata": {
        "id": "6923ca8b"
      },
      "source": [
        "### Vanilla Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1cce97",
      "metadata": {
        "id": "ab1cce97"
      },
      "outputs": [],
      "source": [
        "instructions = \"\"\"\n",
        "You will be given a sentence with fruit names, extract those fruit names and assign an emoji to them\n",
        "Return the fruit name and emojis in a python dictionary\n",
        "\"\"\"\n",
        "\n",
        "fruit_names = \"\"\"\n",
        "Apple, Pear, this is an kiwi\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f16ea4",
      "metadata": {
        "id": "38f16ea4",
        "outputId": "5ece75bb-721a-418d-fc89-80d7f303cfaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Apple': '🍎', 'Pear': '🍐', 'kiwi': '🥝'}\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# Make the prompt which combines the instructions w/ the fruit names\n",
        "prompt = (instructions + fruit_names)\n",
        "\n",
        "# Call the LLM\n",
        "output = chat_model([HumanMessage(content=prompt)])\n",
        "\n",
        "print(output.content)\n",
        "print(type(output.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314286b4",
      "metadata": {
        "id": "314286b4",
        "outputId": "c92b1c7d-5e17-4a7e-c61c-970229829f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Apple': '🍎', 'Pear': '🍐', 'kiwi': '🥝'}\n",
            "<class 'dict'>\n"
          ]
        }
      ],
      "source": [
        "output_dict = eval(output.content)\n",
        "\n",
        "print(output_dict)\n",
        "print(type(output_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3909eb29",
      "metadata": {
        "id": "3909eb29"
      },
      "source": [
        "While this worked this time, it's not a long term reliable method for more advanced use cases"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6a0a90d",
      "metadata": {
        "id": "b6a0a90d"
      },
      "source": [
        "### LangChain's Response Schema\n",
        "\n",
        "- LangChain's response schema does two things for us:\n",
        "\n",
        "  1. Autogenerate the a prompt with bonafide format instructions. This is great because I don't need to worry about the prompt engineering side, I'll leave that up to LangChain!\n",
        "\n",
        "  2. Read the output from the LLM and turn it into a proper python object for me\n",
        "\n",
        "- We are going to pull out the song and artist that a user wants to play from a pseudo chat message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc2ba0be",
      "metadata": {
        "id": "dc2ba0be"
      },
      "outputs": [],
      "source": [
        "# The schema we want to output\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"artist\", description=\"The name of the musical artist\"),\n",
        "    ResponseSchema(name=\"song\", description=\"The name of the song that the artist plays\")\n",
        "]\n",
        "\n",
        "# The parser that will look for the LLM output in the schema and return it back\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9e3c6cf",
      "metadata": {
        "id": "f9e3c6cf",
        "outputId": "edf761e6-fb59-4190-f852-9523dff23609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"artist\": string  // The name of the musical artist\n",
            "\t\"song\": string  // The name of the song that the artist plays\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# The format instructions provided by LangChain\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d702900c",
      "metadata": {
        "id": "d702900c"
      },
      "outputs": [],
      "source": [
        "# The prompt template that brings it all together\n",
        "# Note: This is a different prompt template than before because we are using a Chat Model\n",
        "\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        HumanMessagePromptTemplate.from_template(\"Given a command from the user, extract the artist and song names \\n \\\n",
        "                                                    {format_instructions}\\n{user_prompt}\")\n",
        "    ],\n",
        "    input_variables=[\"user_prompt\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb6adde9",
      "metadata": {
        "id": "bb6adde9",
        "outputId": "acdd8278-c6d7-4c7e-c7e7-26b3fc6ad779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a command from the user, extract the artist and song names \n",
            "                                                     The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"artist\": string  // The name of the musical artist\n",
            "\t\"song\": string  // The name of the song that the artist plays\n",
            "}\n",
            "```\n",
            "I really like Sugar by Maroon 5\n"
          ]
        }
      ],
      "source": [
        "my_query = prompt.format_prompt(user_prompt=\"I really like Sugar by Maroon 5\")\n",
        "print(my_query.messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8664302",
      "metadata": {
        "id": "b8664302",
        "outputId": "dacf341f-01b1-48ce-fa54-45ea7b8b2fe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'artist': 'Maroon 5', 'song': 'Sugar'}\n"
          ]
        }
      ],
      "source": [
        "chat_model_output = chat_model(my_query.to_messages())\n",
        "output = output_parser.parse(chat_model_output.content)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b68b8eeb",
      "metadata": {
        "id": "b68b8eeb"
      },
      "source": [
        "Now we have a dictionary that we can use later down the line\n",
        "\n",
        "<span style=\"background:#fff5d6\">Warning:</span> The parser looks for an output from the LLM in a specific format. Your model may not output the same format every time. Make sure to handle errors with this one. GPT4 and future iterations will be more reliable.\n",
        "\n",
        "For more advanced parsing, please check out [Kor](https://eyurtsev.github.io/kor/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2fb4ba6",
      "metadata": {
        "id": "f2fb4ba6"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Evaluation is the process of doing quality checks on the output of your applications. Normal, deterministic, code has tests we can run, but judging the output of LLMs is more difficult because of the unpredictableness and variability of natural language. LangChain provides tools that aid us in this journey.\n",
        "\n",
        "* **Examples** - [Lance Martin's Advanced](https://twitter.com/RLanceMartin) [Auto-Evaluator](https://github.com/rlancemartin/auto-evaluator)\n",
        "* **Use Cases:** Run quality checks on your summarization or Question & Answer pipelines, check the output of you summarization pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fbaa6e1",
      "metadata": {
        "id": "9fbaa6e1"
      },
      "outputs": [],
      "source": [
        "# Embeddings, store, and retrieval\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Model and doc loader\n",
        "from langchain import OpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Eval\n",
        "from langchain.evaluation.qa import QAEvalChain\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f35fa12",
      "metadata": {
        "id": "9f35fa12",
        "outputId": "37910156-c30c-406f-c50f-5afbca4423dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 1 document\n",
            "You have 74663 characters in that document\n"
          ]
        }
      ],
      "source": [
        "# Our long essay from before\n",
        "loader = TextLoader('data/PaulGrahamEssays/worked.txt')\n",
        "doc = loader.load()\n",
        "\n",
        "print (f\"You have {len(doc)} document\")\n",
        "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7acca7da",
      "metadata": {
        "id": "7acca7da"
      },
      "source": [
        "Build VectoreStore so we can do question and answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1955faef",
      "metadata": {
        "id": "1955faef",
        "outputId": "90b71d56-a0de-4f0b-c30e-0058c30e7ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now you have 29 documents that have an average of 2,930 characters (smaller pieces)\n"
          ]
        }
      ],
      "source": [
        "# Build VectoreStore\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
        "docs = text_splitter.split_documents(doc)\n",
        "\n",
        "num_total_characters = sum([len(x.page_content) for x in docs])\n",
        "\n",
        "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "890b85ca",
      "metadata": {
        "id": "890b85ca"
      },
      "outputs": [],
      "source": [
        "# Embeddings and docstore\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "docsearch = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a0d6e25",
      "metadata": {
        "id": "7a0d6e25"
      },
      "source": [
        "Make a retrieval chain.\n",
        "- `input_key` parameter tells the chain which key from a dictionary I supply has our prompt/query in it.\n",
        "- We specify `question` to match the question in the dict below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddb3f3b5",
      "metadata": {
        "id": "ddb3f3b5"
      },
      "outputs": [],
      "source": [
        "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(), input_key=\"question\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d93d08bf",
      "metadata": {
        "id": "d93d08bf"
      },
      "outputs": [],
      "source": [
        "question_answers = [\n",
        "    {'question' : \"Which company sold the microcomputer kit that his friend built himself?\", 'answer' : 'Healthkit'},\n",
        "    {'question' : \"What was the small city he talked about in the city that is the financial capital of USA?\", 'answer' : 'Yorkville, NY'}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98c4b591",
      "metadata": {
        "id": "98c4b591"
      },
      "source": [
        "We use `chain.apply` to run the questions one by one.\n",
        "\n",
        "We'll get our list of question and answers dictionaries back, but there'll be another key in the dictionary `result` which will be the output from the LLM.\n",
        "\n",
        "*Note: we specifically made the 2nd question ambigious and tough to answer in one pass so the LLM would get it incorrect*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a4e041",
      "metadata": {
        "id": "a4a4e041",
        "outputId": "1e6fbd97-48fe-43d1-9fe6-86b027997008"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'Which company sold the microcomputer kit that his friend built himself?',\n",
              "  'answer': 'Healthkit',\n",
              "  'result': ' The microcomputer kit was sold by Heathkit.'},\n",
              " {'question': 'What was the small city he talked about in the city that is the financial capital of USA?',\n",
              "  'answer': 'Yorkville, NY',\n",
              "  'result': ' The small city he talked about is New York City, which is the financial capital of the United States.'}]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = chain.apply(question_answers)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed1226c9",
      "metadata": {
        "id": "ed1226c9"
      },
      "source": [
        "We then have the LLM compare the ground truth answer (the `answer` key) with the result from the LLM (`result` key).\n",
        "\n",
        "Or simply, we are asking the LLM to grade itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae119b18",
      "metadata": {
        "id": "ae119b18"
      },
      "outputs": [],
      "source": [
        "# Start eval chain\n",
        "eval_chain = QAEvalChain.from_llm(llm)\n",
        "\n",
        "# Have it grade itself. The code below helps the eval_chain know where the different parts are\n",
        "graded_outputs = eval_chain.evaluate(question_answers,\n",
        "                                     predictions,\n",
        "                                     question_key=\"question\",\n",
        "                                     prediction_key=\"result\",\n",
        "                                     answer_key='answer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2882750",
      "metadata": {
        "id": "c2882750",
        "outputId": "e497255f-acbf-416d-c32f-d6115154958d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': ' CORRECT'}, {'text': ' INCORRECT'}]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graded_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b30268b",
      "metadata": {
        "id": "5b30268b"
      },
      "source": [
        "\n",
        "\n",
        "For #1, it was \"Healthkit\" and the prediction was \"The microcomputer kit was sold by Heathkit.\"\n",
        "\n",
        "The LLM knew that the answer and result were the same and gave us the label: `correct` .\n",
        "\n",
        "For #2, it knew they were not the same and gave us the label: `incorrect` ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2745752",
      "metadata": {
        "id": "d2745752"
      },
      "source": [
        "## Querying Tabular Data\n",
        "\n",
        "It is super powerful to be able to query this data with LangChain and pass it through to an LLM.\n",
        "\n",
        "* **Use Cases:** Use LLMs to query data about users, do data analysis, get real time information from your DBs\n",
        "* For futher reading, plz check out **Agents + Tabular Data** ([Pandas](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/pandas.html), [SQL](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html), [CSV](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/csv.html))\n",
        "\n",
        "Let's query an SQLite DB with natural language. We'll look at the [San Francisco Trees](https://data.sfgov.org/City-Infrastructure/Street-Tree-List/tkzw-k3nq) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b19c2d0",
      "metadata": {
        "id": "9b19c2d0"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6044d54e",
      "metadata": {
        "id": "6044d54e"
      },
      "outputs": [],
      "source": [
        "# Set the db path\n",
        "sqlite_db_path = 'data/San_Francisco_Trees.db'\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dccf0957",
      "metadata": {
        "id": "dccf0957",
        "outputId": "fbd68166-bdfc-4842-c0e9-15783d6237d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/gregorykamradt/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/sql_database/base.py:63: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create a chain that takes the LLM and DB\n",
        "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99cdbc44",
      "metadata": {
        "id": "99cdbc44",
        "outputId": "e761a1c4-ce53-4d30-dd5b-7b81787a50fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "How many Species of trees are there in San Francisco?\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(DISTINCT \"qSpecies\") FROM \"SFTrees\";\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[(578,)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3mThere are 578 Species of trees in San Francisco.\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'There are 578 Species of trees in San Francisco.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db_chain.run(\"How many Species of trees are there in San Francisco?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bd61598",
      "metadata": {
        "id": "6bd61598"
      },
      "source": [
        "There are actually a few steps going on here:\n",
        "1. Find which table to use\n",
        "2. Find which column to use\n",
        "3. Construct the correct sql query\n",
        "4. Execute that query\n",
        "5. Get the result\n",
        "6. Return a natural language reponse back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "299ff6ca",
      "metadata": {
        "id": "299ff6ca"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to the SQLite database\n",
        "connection = sqlite3.connect(sqlite_db_path)\n",
        "\n",
        "# Define SQL query\n",
        "query = \"SELECT count(distinct qSpecies) FROM SFTrees\"\n",
        "\n",
        "# Read the SQL query into a Pandas DataFrame\n",
        "df = pd.read_sql_query(query, connection)\n",
        "\n",
        "# Close connection\n",
        "connection.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b2dd89",
      "metadata": {
        "id": "f1b2dd89",
        "outputId": "f36be6f2-eaec-40a8-a954-46f1110cc161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "578\n"
          ]
        }
      ],
      "source": [
        "# Display the result in the first column first cell\n",
        "print(df.iloc[0,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b2783a",
      "metadata": {
        "id": "f3b2783a"
      },
      "source": [
        "## Interacting with APIs\n",
        "\n",
        "If the data or action is behind an API, we'll need the LLM to interact with APIs\n",
        "\n",
        "* **Use Cases:** Understand a request from a user and carry out an action, be able to automate more real-world workflows\n",
        "\n",
        "- This topic is closely related to Agents and Plugins, though we'll look at a simple use case for this section. For more information, check out [LangChain + plugins](https://python.langchain.com/en/latest/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6b834fe",
      "metadata": {
        "id": "e6b834fe"
      },
      "source": [
        "LangChain's `APIChain` has the ability to read API documentation and understand which endpoint it needs to call.\n",
        "\n",
        "Below is a purposefully sloppy API documentation to demonstrate how this works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "352685c0",
      "metadata": {
        "id": "352685c0"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import APIChain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff4b986",
      "metadata": {
        "id": "3ff4b986"
      },
      "outputs": [],
      "source": [
        "api_docs = \"\"\"\n",
        "\n",
        "BASE URL: https://restcountries.com/\n",
        "\n",
        "API Documentation:\n",
        "\n",
        "The API endpoint /v3.1/name/{name} Used to find informatin about a country. All URL parameters are listed below:\n",
        "    - name: Name of country - Ex: italy, france\n",
        "\n",
        "The API endpoint /v3.1/currency/{currency} Uesd to find information about a region. All URL parameters are listed below:\n",
        "    - currency: 3 letter currency. Example: USD, COP\n",
        "\n",
        "Woo! This is my documentation\n",
        "\"\"\"\n",
        "\n",
        "chain_new = APIChain.from_llm_and_api_docs(llm, api_docs, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d9cae4",
      "metadata": {
        "id": "e6d9cae4",
        "outputId": "0ab5ebcb-ca8b-4e16-fc2a-2b956e14f0aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/name/france\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"France\",\"official\":\"French Republic\",\"nativeName\":{\"fra\":{\"official\":\"République française\",\"common\":\"France\"}}},\"tld\":[\".fr\"],\"cca2\":\"FR\",\"ccn3\":\"250\",\"cca3\":\"FRA\",\"cioc\":\"FRA\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"EUR\":{\"name\":\"Euro\",\"symbol\":\"€\"}},\"idd\":{\"root\":\"+3\",\"suffixes\":[\"3\"]},\"capital\":[\"Paris\"],\"altSpellings\":[\"FR\",\"French Republic\",\"République française\"],\"region\":\"Europe\",\"subregion\":\"Western Europe\",\"languages\":{\"fra\":\"French\"},\"translations\":{\"ara\":{\"official\":\"الجمهورية الفرنسية\",\"common\":\"فرنسا\"},\"bre\":{\"official\":\"Republik Frañs\",\"common\":\"Frañs\"},\"ces\":{\"official\":\"Francouzská republika\",\"common\":\"Francie\"},\"cym\":{\"official\":\"French Republic\",\"common\":\"France\"},\"deu\":{\"official\":\"Französische Republik\",\"common\":\"Frankreich\"},\"est\":{\"official\":\"Prantsuse Vabariik\",\"common\":\"Prantsusmaa\"},\"fin\":{\"official\":\"Ranskan tasavalta\",\"common\":\"Ranska\"},\"fra\":{\"official\":\"République française\",\"common\":\"France\"},\"hrv\":{\"official\":\"Francuska Republika\",\"common\":\"Francuska\"},\"hun\":{\"official\":\"Francia Köztársaság\",\"common\":\"Franciaország\"},\"ita\":{\"official\":\"Repubblica francese\",\"common\":\"Francia\"},\"jpn\":{\"official\":\"フランス共和国\",\"common\":\"フランス\"},\"kor\":{\"official\":\"프랑스 공화국\",\"common\":\"프랑스\"},\"nld\":{\"official\":\"Franse Republiek\",\"common\":\"Frankrijk\"},\"per\":{\"official\":\"جمهوری فرانسه\",\"common\":\"فرانسه\"},\"pol\":{\"official\":\"Republika Francuska\",\"common\":\"Francja\"},\"por\":{\"official\":\"República Francesa\",\"common\":\"França\"},\"rus\":{\"official\":\"Французская Республика\",\"common\":\"Франция\"},\"slk\":{\"official\":\"Francúzska republika\",\"common\":\"Francúzsko\"},\"spa\":{\"official\":\"República francés\",\"common\":\"Francia\"},\"srp\":{\"official\":\"Француска Република\",\"common\":\"Француска\"},\"swe\":{\"official\":\"Republiken Frankrike\",\"common\":\"Frankrike\"},\"tur\":{\"official\":\"Fransa Cumhuriyeti\",\"common\":\"Fransa\"},\"urd\":{\"official\":\"جمہوریہ فرانس\",\"common\":\"فرانس\"},\"zho\":{\"official\":\"法兰西共和国\",\"common\":\"法国\"}},\"latlng\":[46.0,2.0],\"landlocked\":false,\"borders\":[\"AND\",\"BEL\",\"DEU\",\"ITA\",\"LUX\",\"MCO\",\"ESP\",\"CHE\"],\"area\":551695.0,\"demonyms\":{\"eng\":{\"f\":\"French\",\"m\":\"French\"},\"fra\":{\"f\":\"Française\",\"m\":\"Français\"}},\"flag\":\"\\uD83C\\uDDEB\\uD83C\\uDDF7\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/g7QxxSFsWyTPKuzd7\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/1403916\"},\"population\":67391582,\"gini\":{\"2018\":32.4},\"fifa\":\"FRA\",\"car\":{\"signs\":[\"F\"],\"side\":\"right\"},\"timezones\":[\"UTC-10:00\",\"UTC-09:30\",\"UTC-09:00\",\"UTC-08:00\",\"UTC-04:00\",\"UTC-03:00\",\"UTC+01:00\",\"UTC+02:00\",\"UTC+03:00\",\"UTC+04:00\",\"UTC+05:00\",\"UTC+10:00\",\"UTC+11:00\",\"UTC+12:00\"],\"continents\":[\"Europe\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/fr.png\",\"svg\":\"https://flagcdn.com/fr.svg\",\"alt\":\"The flag of France is composed of three equal vertical bands of blue, white and red.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/fr.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/fr.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[48.87,2.33]},\"postalCode\":{\"format\":\"#####\",\"regex\":\"^(\\\\d{5})$\"}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' France is an officially-assigned, independent country located in Western Europe. Its capital is Paris and its official language is French. Its currency is the Euro (€). It has a population of 67,391,582 and its borders are with Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain, and Switzerland.'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# make an API call for the country endpoint\n",
        "chain_new.run('Can you tell me information about france?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2735073",
      "metadata": {
        "id": "c2735073",
        "outputId": "79594be2-0a39-43a3-8ef7-a36b4957caa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/currency/COP\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Colombia\",\"official\":\"Republic of Colombia\",\"nativeName\":{\"spa\":{\"official\":\"República de Colombia\",\"common\":\"Colombia\"}}},\"tld\":[\".co\"],\"cca2\":\"CO\",\"ccn3\":\"170\",\"cca3\":\"COL\",\"cioc\":\"COL\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"COP\":{\"name\":\"Colombian peso\",\"symbol\":\"$\"}},\"idd\":{\"root\":\"+5\",\"suffixes\":[\"7\"]},\"capital\":[\"Bogotá\"],\"altSpellings\":[\"CO\",\"Republic of Colombia\",\"República de Colombia\"],\"region\":\"Americas\",\"subregion\":\"South America\",\"languages\":{\"spa\":\"Spanish\"},\"translations\":{\"ara\":{\"official\":\"جمهورية كولومبيا\",\"common\":\"كولومبيا\"},\"bre\":{\"official\":\"Republik Kolombia\",\"common\":\"Kolombia\"},\"ces\":{\"official\":\"Kolumbijská republika\",\"common\":\"Kolumbie\"},\"cym\":{\"official\":\"Gweriniaeth Colombia\",\"common\":\"Colombia\"},\"deu\":{\"official\":\"Republik Kolumbien\",\"common\":\"Kolumbien\"},\"est\":{\"official\":\"Colombia Vabariik\",\"common\":\"Colombia\"},\"fin\":{\"official\":\"Kolumbian tasavalta\",\"common\":\"Kolumbia\"},\"fra\":{\"official\":\"République de Colombie\",\"common\":\"Colombie\"},\"hrv\":{\"official\":\"Republika Kolumbija\",\"common\":\"Kolumbija\"},\"hun\":{\"official\":\"Kolumbiai Köztársaság\",\"common\":\"Kolumbia\"},\"ita\":{\"official\":\"Repubblica di Colombia\",\"common\":\"Colombia\"},\"jpn\":{\"official\":\"コロンビア共和国\",\"common\":\"コロンビア\"},\"kor\":{\"official\":\"콜롬비아 공화국\",\"common\":\"콜롬비아\"},\"nld\":{\"official\":\"Republiek Colombia\",\"common\":\"Colombia\"},\"per\":{\"official\":\"جمهوری کلمبیا\",\"common\":\"کلمبیا\"},\"pol\":{\"official\":\"Republika Kolumbii\",\"common\":\"Kolumbia\"},\"por\":{\"official\":\"República da Colômbia\",\"common\":\"Colômbia\"},\"rus\":{\"official\":\"Республика Колумбия\",\"common\":\"Колумбия\"},\"slk\":{\"official\":\"Kolumbijská republika\",\"common\":\"Kolumbia\"},\"spa\":{\"official\":\"República de Colombia\",\"common\":\"Colombia\"},\"srp\":{\"official\":\"Република Колумбија\",\"common\":\"Колумбија\"},\"swe\":{\"official\":\"Republiken Colombia\",\"common\":\"Colombia\"},\"tur\":{\"official\":\"Kolombiya Cumhuriyeti\",\"common\":\"Kolombiya\"},\"urd\":{\"official\":\"جمہوریہ کولمبیا\",\"common\":\"کولمبیا\"},\"zho\":{\"official\":\"哥伦比亚共和国\",\"common\":\"哥伦比亚\"}},\"latlng\":[4.0,-72.0],\"landlocked\":false,\"borders\":[\"BRA\",\"ECU\",\"PAN\",\"PER\",\"VEN\"],\"area\":1141748.0,\"demonyms\":{\"eng\":{\"f\":\"Colombian\",\"m\":\"Colombian\"},\"fra\":{\"f\":\"Colombienne\",\"m\":\"Colombien\"}},\"flag\":\"\\uD83C\\uDDE8\\uD83C\\uDDF4\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/RdwTG8e7gPwS62oR6\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/120027\"},\"population\":50882884,\"gini\":{\"2019\":51.3},\"fifa\":\"COL\",\"car\":{\"signs\":[\"CO\"],\"side\":\"right\"},\"timezones\":[\"UTC-05:00\"],\"continents\":[\"South America\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/co.png\",\"svg\":\"https://flagcdn.com/co.svg\",\"alt\":\"The flag of Colombia is composed of three horizontal bands of yellow, blue and red, with the yellow band twice the height of the other two bands.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/co.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/co.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[4.71,-74.07]}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' The currency of Colombia is the Colombian peso (COP), symbolized by the \"$\" sign.'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# make an API call for the currency COP\n",
        "chain_new.run('Can you tell me about the currency COP?')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d5be7e0",
      "metadata": {
        "id": "2d5be7e0"
      },
      "source": [
        "In both cases the APIChain read the instructions and understood which API call it needed to make.\n",
        "\n",
        "Once the response returned, it was parsed and then my question was answered. Awesome 🐒"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90e0f275"
      },
      "source": [
        "## Chatbots\n",
        "\n",
        "\n",
        "Chatbots use many of the tools with the addition of an important topic: Memory.\n",
        "\n",
        "* **Examples** - [ChatBase](https://www.chatbase.co/?via=greg) (Affiliate link), [NexusGPT](https://twitter.com/achammah1/status/1649482899253501958?s=20), [ChatPDF](https://www.chatpdf.com/)\n",
        "* **Use Cases:** Have a real time interaction with a user, provide an approachable UI for users to ask natural language questions.\n",
        "- There are a ton of different [types of memory](https://python.langchain.com/en/latest/modules/memory/how_to_guides.html)."
      ],
      "id": "90e0f275"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dca0672"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "# Chat specific components\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "id": "7dca0672"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53b86e88"
      },
      "source": [
        "For this use case, we will customize the context that is given to a chatbot.\n",
        "\n",
        "We could pass instructions on how the bot should respond, but also any additional relevant information it needs."
      ],
      "id": "53b86e88"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "547aefa1"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "You are a chatbot that is unhelpful.\n",
        "Your goal is to not help the user but only make jokes.\n",
        "Take what the user is saying and make a joke out of it\n",
        "\n",
        "{chat_history}\n",
        "Human: {human_input}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"human_input\"],\n",
        "    template=template\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "id": "547aefa1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "475822a0"
      },
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(openai_api_key=openai_api_key),\n",
        "    prompt=prompt,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")"
      ],
      "id": "475822a0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20ae6e3d",
        "outputId": "cc76b45d-3cd0-4439-9203-f8d8883f7779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a chatbot that is unhelpful.\n",
            "Your goal is to not help the user but only make jokes.\n",
            "Take what the user is saying and make a joke out of it\n",
            "\n",
            "\n",
            "Human: Is an pear a fruit or vegetable?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Well, it depends on if you're a fruit or vegetable person!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "llm_chain.predict(human_input=\"Is an pear a fruit or vegetable?\")"
      ],
      "id": "20ae6e3d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd87e2a9",
        "outputId": "6e7acbfd-d966-46b8-f6db-605eb24120d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a chatbot that is unhelpful.\n",
            "Your goal is to not help the user but only make jokes.\n",
            "Take what the user is saying and make a joke out of it\n",
            "\n",
            "Human: Is an pear a fruit or vegetable?\n",
            "AI:  Well, it depends on if you're a fruit or vegetable person!\n",
            "Human: What was one of the fruits I first asked you about?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' An apple a day keeps the doctor away!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "llm_chain.predict(human_input=\"What was one of the fruits I first asked you about?\")"
      ],
      "id": "bd87e2a9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KgncsV9c1Hp0",
        "t_Ys-kVNACur",
        "qsjv_W83APPR",
        "PQd4LA3OAPPS",
        "BYalAEb3APPT",
        "e7-Ov28aAPPU",
        "BElYw_Y8APPU",
        "kOlzr_8iAPPV",
        "UAkpA-wZuPv1",
        "a2d664fc",
        "1bbdb1dc",
        "kXfs7y3rKxOW",
        "prkNs0JIF9QM",
        "f2fb4ba6",
        "d2745752",
        "90e0f275"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}